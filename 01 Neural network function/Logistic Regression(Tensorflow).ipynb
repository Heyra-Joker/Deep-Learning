{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow\n",
    "\n",
    "[TF](https://tensorflow.google.cn/api_docs/python/)使用的是计算图的方式,所以代码看起来会比较难以理解.并且TF是不需要写参数更新的,它将根据你输入的损失函数自行进行参数更新.\n",
    "\n",
    "\n",
    "\n",
    "(1)\n",
    "\n",
    "我们需要先定义占位符[tf.placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)用于反应张量:\n",
    "\n",
    "```python\n",
    "tf.placeholder(tf.float32,shape=[None,n])``` \n",
    "\n",
    "shape中一般只要放入特征值的大小,TF会自动将输入的X塞进去.\n",
    "\n",
    "(2) 创建初始化变量使用[tf.Variable](https://www.tensorflow.org/api_docs/python/tf/Variable)\n",
    "\n",
    "```python \n",
    "tf.Variable(tf.random_normal(shape=[1,n],seed=1))```\n",
    "\n",
    "tf.random_normal:从正态分布输出随机值,seed为随机数种子,shape用于初始化变量定义形状.\n",
    "\n",
    "(3) 矩阵相乘使用[tf.matmul](https://www.tensorflow.org/api_docs/python/tf/linalg/matmul)\n",
    "\n",
    "```python\n",
    "tf.matmul```\n",
    "\n",
    "\n",
    "(4) 计算损失函数可以使用[tf.nn.sigmoid_cross_entropy_with_logits(logits=Z,labels=y)](https://www.tensorflow.org/api_docs/python/tf/nn/sigmoid_cross_entropy_with_logits)\n",
    "\n",
    "```python\n",
    "\n",
    "tf.nn.sigmoid_cross_entropy_with_logits(logits=Z,labels=y)```\n",
    "\n",
    "注意这里logits项会直接帮你计算sigmoid,所以传入的并不是sigmoid作用之后的值,而是线性值.\n",
    "\n",
    "\n",
    "(5) 梯度下降优化器使用[tf.train.GradientDescentOptimizer](https://www.tensorflow.org/api_docs/python/tf/train/GradientDescentOptimizer)\n",
    "\n",
    "```python\n",
    "tf.train.GradientDescentOptimizer```\n",
    "\n",
    "minimize(cost):使用优化器后目的就是最小化minimize,也就是相当于开始参数更新.\n",
    "\n",
    "(6) tf.equal:计算两者是否相等,再使用[tf.cast](https://www.tensorflow.org/api_docs/python/tf/dtypes/cast)转换类型,最后求平均.\n",
    "\n",
    "将需要的代码定义完毕了之后,就可以开始初始化所有的变量[tf.global_variables_initializer()](https://www.tensorflow.org/api_docs/python/tf/initializers/global_variables)\n",
    "\n",
    "```python\n",
    "tf.global_variables_initializer()```\n",
    "\n",
    "\n",
    "(7) 当初始化完毕了之后就可以开始运行计算图了[tf.Session()](https://www.tensorflow.org/api_docs/python/tf/Session)\n",
    "\n",
    "```python\n",
    "sess.run(init)\n",
    "...\n",
    "tf.Session()```\n",
    "\n",
    "一般这一步都是定死的\n",
    "\n",
    "(8) 计算图运行....\n",
    "\n",
    "(9) 运行完毕之后就可以计算正确率:\n",
    "\n",
    "```python\n",
    "accuracy.eval```\n",
    "\n",
    "将需要的数据喂入,即可计算正确率.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 所以TF的整体结构就是:\n",
    "\n",
    "(1) 定义变量和占位符\n",
    "\n",
    "(2) 编写需要的代码(构建网络架构)\n",
    "\n",
    "(3) 初始化所有代码\n",
    "\n",
    "(4) 运行计算图\n",
    "\n",
    "(5) 得到参数更新结果\n",
    "\n",
    "**Ps:**\n",
    "\n",
    "[Tensor类型为什么可以自动求导](https://www.zhihu.com/question/54554389)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    '''\n",
    "    create train set and test set\n",
    "    make sure you have .h5 file in your dataset\n",
    "    \n",
    "    Returns:\n",
    "    -------\n",
    "        train_set_x_orig: original train set shape is (209, 64, 64, 3) \n",
    "        train_set_y_orig: original train label shape is (209,)\n",
    "        test_set_x_orig: original test set shape is (50, 64, 64, 3)\n",
    "        test_set_y_orig: original test label shape is (50,)\n",
    "        classes: cat or non-cat.\n",
    "        \n",
    "    Note:\n",
    "    ----\n",
    "        (209, 64, 64, 3): 209 picture,64 width,64 height,3 channel.\n",
    "    '''\n",
    "    train_dataset = h5py.File('../data_set/train_catvnoncat.h5', \"r\")\n",
    "    train_set_x_orig = np.array(train_dataset[\"train_set_x\"][:]) # your train set features\n",
    "    train_set_y_orig = np.array(train_dataset[\"train_set_y\"][:]) # your train set labels\n",
    "\n",
    "    test_dataset = h5py.File('../data_set/test_catvnoncat.h5', \"r\")\n",
    "    test_set_x_orig = np.array(test_dataset[\"test_set_x\"][:]) # your test set features\n",
    "    test_set_y_orig = np.array(test_dataset[\"test_set_y\"][:]) # your test set labels\n",
    "\n",
    "    classes = np.array(test_dataset[\"list_classes\"][:]) # the list of classes\n",
    "    \n",
    "    return train_set_x_orig, train_set_y_orig, test_set_x_orig, test_set_y_orig, classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_orig, train_y_orig, test_x_orig, test_y_orig, classes = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_x's shape:(209, 12288)\n",
      "Test_x's shape:(50, 12288)\n",
      "Train_y's shape:(1, 209)\n",
      "Test_y's shape:(1, 50)\n"
     ]
    }
   ],
   "source": [
    "train_x_tensor = train_x_orig.reshape(train_x_orig.shape[0],-1) / 255 \n",
    "test_x_tensor = test_x_orig.reshape(test_x_orig.shape[0],-1) / 255\n",
    "train_y_tensor = train_y_orig.reshape(1,-1)\n",
    "test_y_tensor = test_y_orig.reshape(1,-1)\n",
    "print('Train_x\\'s shape:{}'.format(train_x_tensor.shape))\n",
    "print('Test_x\\'s shape:{}'.format(test_x_tensor.shape))\n",
    "print(\"Train_y's shape:{}\".format(train_y_tensor.shape))\n",
    "print(\"Test_y's shape:{}\".format(test_y_tensor.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initial_parameters(n):\n",
    "    \"\"\"\n",
    "    initialization parameters\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "        n: fetures\n",
    "    Returns:\n",
    "        W:TF variable,weigths\n",
    "        b:TF variable,bais\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    W = tf.Variable(tf.random_normal(shape=[1,n],seed=1))\n",
    "    b = tf.Variable(tf.zeros(shape=[1,1]))\n",
    "    \n",
    "    return W,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LR_Tensorflow(data,Labels,test_data,test_label,alpha,Iter):\n",
    "    \"\"\"\n",
    "    Build LR Tensorflow\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "        data: training set\n",
    "        Labels: training set\n",
    "        test_data: test set\n",
    "        test_label: test labels\n",
    "        alpha: learning rate\n",
    "        Iter: iterate\n",
    "    \n",
    "    \"\"\"\n",
    "   \n",
    "    m,n = data.shape\n",
    "    \n",
    "    # create placeholder.\n",
    "    X = tf.placeholder(tf.float32,shape=[None,n]) # shape is (None,n)\n",
    "    y = tf.placeholder(tf.float32,shape=[1,None])\n",
    "    \n",
    "    # initialization parameters\n",
    "    W,b = initial_parameters(n)\n",
    "    \n",
    "    # calculate learn Regression.\n",
    "    Z = tf.matmul(W,tf.transpose(X)) + b\n",
    "    \n",
    "    # compute cost \n",
    "    cost = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=Z,labels=y))\n",
    "    \n",
    "    # using optimization of Gradient Descent and minimize cost.\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate=alpha).minimize(cost)\n",
    "    \n",
    "    # calculate correct rate\n",
    "    correct_ = tf.equal(tf.round(tf.sigmoid(Z)),y)\n",
    "        \n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_,tf.float32))\n",
    "    \n",
    "    # initialization variable.\n",
    "    init = tf.global_variables_initializer()\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        \n",
    "        sess.run(init)\n",
    "\n",
    "        for iter_ in range(Iter):\n",
    "            \n",
    "            # return value equal list size.\n",
    "            # need feed dict,how many placeholder how many value.\n",
    "            _,c = sess.run([optimizer,cost],feed_dict={X:data,y:Labels})\n",
    "           \n",
    "            if iter_ % 100 == 0:\n",
    "                \n",
    "                print('after iter {},loss {}'.format(iter_,c))\n",
    "        \n",
    "        # input data and labels to calculateaccuracy.\n",
    "        correct_rate_test = accuracy.eval({X:test_data,y:test_label })\n",
    "        correct_rate_train = accuracy.eval({X:data,y:Labels})\n",
    "        print(\"The test set correct is \",correct_rate_test)\n",
    "        print(\"The train set correct is \",correct_rate_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after iter 0,loss 7.985492706298828\n",
      "after iter 100,loss 3.4039981365203857\n",
      "after iter 200,loss 14.464579582214355\n",
      "after iter 300,loss 1.3415228128433228\n",
      "after iter 400,loss 9.29128646850586\n",
      "after iter 500,loss 4.443009376525879\n",
      "after iter 600,loss 1.3032474517822266\n",
      "after iter 700,loss 0.31220778822898865\n",
      "after iter 800,loss 0.1305931806564331\n",
      "after iter 900,loss 0.22720423340797424\n",
      "after iter 1000,loss 0.043595489114522934\n",
      "The test set correct is  0.6\n",
      "The train set correct is  0.9952153\n"
     ]
    }
   ],
   "source": [
    "LR_Tensorflow(train_x_tensor,train_y_tensor,test_x_tensor,test_y_tensor,0.1,1100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "可以看出TF集成了许多可用的函数,整体的逻辑思路也是一样的,只是我们要先建立一些tensor,比如placeholder.接着还是一样的先正向传播再计算loss,定义优化器optimizer,之后反向传播,接着更新参数.只要熟悉TF框架的定义,那么模型代码就会变得简单.\n",
    "\n",
    "另外由于tensor的存在,使得我们不需要进行backward,这是非常方便的,因为在之后随着模型深度加深以及一些其他优化措施下,推导backward是非常困难的,而且如果只是使用Numpy定义,计算速度也是非常的慢."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
