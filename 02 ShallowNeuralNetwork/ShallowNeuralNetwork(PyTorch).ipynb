{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ShallowNeuralNetwork(PyTorch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from sklearn import datasets\n",
    "from torch.autograd import Variable\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 Load Data\n",
    "\n",
    "这里我们使用sklearn中的iris数据集."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadData_iris():\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "    --------\n",
    "        X:have two dimensions (sepal length and width).\n",
    "        Y:labels.\n",
    "    \"\"\"\n",
    "    iris = datasets.load_iris()\n",
    "    X = iris.data[:100, :2]\n",
    "    Y = iris.target[:100]\n",
    "    return X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape is: (100, 2)\n",
      "y shape is: (100,)\n"
     ]
    }
   ],
   "source": [
    "X,y = loadData_iris()\n",
    "print('X shape is:',X.shape)\n",
    "print('y shape is:',y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 Split data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (80, 2)\n",
      "X_test shape: (20, 2)\n",
      "y_train shape: (80, 1)\n",
      "y_test shape: (20, 1)\n"
     ]
    }
   ],
   "source": [
    "y_train = y_train.reshape(-1,1)\n",
    "y_test = y_test.reshape(-1,1)\n",
    "\n",
    "print('X_train shape:',X_train.shape)\n",
    "print('X_test shape:',X_test.shape)\n",
    "print('y_train shape:',y_train.shape)\n",
    "print('y_test shape:',y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 Build Pytorch Model\n",
    "\n",
    "#### 2.1 change type to tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = Variable(torch.Tensor(X_train))\n",
    "X_test = Variable(torch.Tensor(X_test))\n",
    "y_train = Variable(torch.Tensor(y_train))\n",
    "y_test = Variable(torch.Tensor(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在使用线性计算时需要注意:\n",
    "\n",
    "```python\n",
    "torch.nn.Linear(in_features, out_features, bias=True)```\n",
    "\n",
    "**Example:**\n",
    "\n",
    "```python\n",
    "m = nn.Linear(20, 30)\n",
    "input = torch.randn(128, 20)\n",
    "output = m(input)\n",
    "print(output.size())\n",
    "torch.Size([128, 30])```\n",
    "\n",
    "\n",
    "可以看到,如果```in_features=20,out_features=30```,那么最后的输出为30.也就是说,最后输出的是shape(m,out_features).\n",
    "\n",
    "那么我们喂入的样本形状需要是(m,n)的形式.\n",
    "\n",
    "以我们现在的案例来讲:\n",
    "\n",
    "```self.line1 = torch.nn.Linear(n,4)```输出的是shape(m,4)\n",
    "\n",
    "```self.line2 = torch.nn.Linear(4,1)```输出的是shape(m,1)\n",
    "\n",
    "所以我们的labels形状需要是(m,1).这样我们才可以进一步计算loss.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 build class\n",
    "\n",
    "(1) 定义hidden layer-1:\n",
    "\n",
    "```python\n",
    "\n",
    "self.line1 = torch.nn.Linear(n,4)\n",
    "Z1 = self.line1(X)\n",
    "A1 = torch.relu(Z1)```\n",
    "\n",
    "(2) 定义hidden layer-2:\n",
    "\n",
    "```python\n",
    "self.line2 = torch.nn.Linear(4,1)\n",
    "Z2 = self.line2(A1)\n",
    "A2 = torch.sigmoid(Z2)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class shallowNN(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    torch class:define NN\n",
    "    Parameters:\n",
    "    ----------\n",
    "        n: number features.\n",
    "    Return:\n",
    "    ------\n",
    "        A2: layer-2:sigmoid value.\n",
    "    \"\"\"\n",
    "    def __init__(self,n):\n",
    "        torch.nn.Module.__init__(self)\n",
    "        self.line1 = torch.nn.Linear(n,4) # linear function,Note this parameters.\n",
    "        self.line2 = torch.nn.Linear(4,1)\n",
    "        \n",
    "    def forward(self,X):\n",
    "        \"\"\"\n",
    "        Forward propagation\n",
    "        Prameters:\n",
    "        ---------\n",
    "            X: data set\n",
    "        \"\"\"\n",
    "        Z1 = self.line1(X)\n",
    "        A1 = torch.relu(Z1)\n",
    "        Z2 = self.line2(A1)\n",
    "        A2 = torch.sigmoid(Z2)\n",
    "        return A2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 Build SNN\n",
    "\n",
    "(1) 初始化模型:\n",
    "\n",
    "```python\n",
    "model = shallowNN(n)```\n",
    "\n",
    "(2) 初始化二分类损失熵:\n",
    "\n",
    "```python\n",
    "ceriterion = torch.nn.BCELoss(reduction='mean')```\n",
    "\n",
    "(3) 初始化优化器:\n",
    "\n",
    "```python\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr=alpha)```\n",
    "\n",
    "(4) 重置梯度值:\n",
    "\n",
    "Pytorch在梯度计算方面是使用累加的方式\n",
    "\n",
    "```python\n",
    "optimizer.zero_grad()```\n",
    "\n",
    "(5) 计算反向传播:\n",
    "\n",
    "```python\n",
    "loss.backward()```\n",
    "\n",
    "(6) 更新所有参数:\n",
    "\n",
    "```python\n",
    "optimizer.step()```\n",
    "\n",
    "(7) 返回Forward以便于测试正确率:\n",
    "\n",
    "```python\n",
    "model.forward```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ShallowNN_model(X,y,alpha,Iter,is_print=False):\n",
    "    \"\"\"\n",
    "    Build SNN\n",
    "    \n",
    "    parameters:\n",
    "    ----------\n",
    "       X: training data set\n",
    "       y: training labels\n",
    "       alpha: learning rate\n",
    "       Iter: iterative number\n",
    "       is_print: print loss.\n",
    "       \n",
    "    Return:\n",
    "    ------\n",
    "       model.forward: forward propagation: caclulate accuracy. \n",
    "    \"\"\"\n",
    "    m,n = X.shape\n",
    "    model = shallowNN(n)\n",
    "    \n",
    "    ceriterion = torch.nn.BCELoss(reduction='mean')\n",
    "    optimizer = torch.optim.SGD(model.parameters(),lr=alpha)\n",
    "    \n",
    "    for iter_ in range(Iter):\n",
    "        \n",
    "        A2 = model.forward(X)\n",
    "        loss = ceriterion(A2,y)\n",
    "        \n",
    "        if iter_ % 100 ==0 and is_print:\n",
    "            print('After iter {} loss: {}'.format(iter_,loss))\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    \n",
    "    return model.forward\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After iter 0 loss: 0.7204402089118958\n",
      "After iter 100 loss: 0.3151532709598541\n",
      "After iter 200 loss: 0.1036759465932846\n"
     ]
    }
   ],
   "source": [
    "forward = ShallowNN_model(X_train,y_train,0.1,300,True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4 predict and score\n",
    "\n",
    "下面查看一下测试,训练样本的正确率."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_score(X,y,forward_func):\n",
    "    \"\"\"\n",
    "    predict and score\n",
    "    Parameters:\n",
    "    ----------\n",
    "        X: data set\n",
    "        y: labels\n",
    "        forward_func: forward propagation\n",
    "    \n",
    "    Return:\n",
    "    ------\n",
    "        accuracy: correct rate.\n",
    "    \"\"\"\n",
    "    m,n = X.shape\n",
    "    predict_y = torch.round(forward_func(X))\n",
    "    accuracy = torch.sum((predict_y == y)).item() / m\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test data set accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "accuracy = predict_score(X_test,y_test,forward)\n",
    "print('The test data set accuracy:',accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train data set accuracy: 0.9875\n"
     ]
    }
   ],
   "source": [
    "accuracy = predict_score(X_train,y_train,forward)\n",
    "print('The train data set accuracy:',accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
