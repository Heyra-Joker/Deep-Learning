{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Checking\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) How does gradient checking work?\n",
    "Backpropagation computes the gradients $\\frac{\\partial J}{\\partial \\theta}$, where $\\theta$ denotes the parameters of the model. $J$ is computed using forward propagation and your loss function.\n",
    "\n",
    "Because forward propagation is relatively easy to implement, you're confident you got that right, and so you're almost 100% sure that you're computing the cost $J$ correctly. Thus, you can use your code for computing $J$ to verify the code for computing $\\frac{\\partial J}{\\partial \\theta}$.\n",
    "\n",
    "Let's look back at the definition of a derivative (or gradient): $$ \\frac{\\partial J}{\\partial \\theta} = \\lim_{\\varepsilon \\to 0} \\frac{J(\\theta + \\varepsilon) - J(\\theta - \\varepsilon)}{2 \\varepsilon} \\tag{1}$$\n",
    "\n",
    "If you're not familiar with the \"$\\displaystyle \\lim_{\\varepsilon \\to 0}$\" notation, it's just a way of saying \"when $\\varepsilon$ is really really small.\"\n",
    "\n",
    "We know the following:\n",
    "\n",
    "$\\frac{\\partial J}{\\partial \\theta}$ is what you want to make sure you're computing correctly.\n",
    "You can compute $J(\\theta + \\varepsilon)$ and $J(\\theta - \\varepsilon)$ (in the case that $\\theta$ is a real number), since you're confident your implementation for $J$ is correct.\n",
    "Lets use equation (1) and a small value for $\\varepsilon$ to convince your CEO that your code for computing  $\\frac{\\partial J}{\\partial \\theta}$ is correct!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) 1-dimensional gradient checking\n",
    "Consider a 1D linear function $J(\\theta) = \\theta x$. The model contains only a single real-valued parameter $\\theta$, and takes $x$ as input.\n",
    "\n",
    "You will implement code to compute $J(.)$ and its derivative $\\frac{\\partial J}{\\partial \\theta}$. You will then use gradient checking to make sure your derivative computation for $J$ is correct.\n",
    "![](../../picture/74.png)\n",
    "The diagram above shows the key computation steps: First start with $x$, then evaluate the function $J(x)$ (\"forward propagation\"). Then compute the derivative $\\frac{\\partial J}{\\partial \\theta}$ (\"backward propagation\").\n",
    "#### Exercise:\n",
    "- implement \"forward propagation\" and \"backward propagation\" for this simple function. I.e., compute both $J(.)$ (\"forward propagation\") and its derivative with respect to $\\theta$ (\"backward propagation\"), in two separate functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagation(x,theta):\n",
    "    '''\n",
    "    Implement the linear forward propagation (compute J) presented in Figure 1 (J(theta) = theta * x)\n",
    "    Arguments:\n",
    "        x :input data\n",
    "        theta: a real number\n",
    "    \n",
    "    '''\n",
    "    J = theta * x\n",
    "    \n",
    "    return J\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise:\n",
    "- Now, implement the backward propagation step (derivative computation) of Figure 1. That is, compute the derivative of $J(\\theta) = \\theta x$ with respect to $\\theta$. To save you from doing the calculus, you should get $dtheta = \\frac { \\partial J }{ \\partial \\theta} = x$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_propagations(x):\n",
    "    '''\n",
    "    Compute derivative of J ---> dJ/dtheta = x\n",
    "    return: dtheta\n",
    "    '''\n",
    "    \n",
    "    dtheta = x\n",
    "    return dtheta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instructions:\n",
    "\n",
    "- First compute \"gradapprox\" using the formula above (1) and a small value of $\\varepsilon$. Here are the Steps to follow:\n",
    "- $\\theta^{+} = \\theta + \\varepsilon$\n",
    "- $\\theta^{-} = \\theta - \\varepsilon$\n",
    "- $J^{+} = J(\\theta^{+})$\n",
    "- $J^{-} = J(\\theta^{-})$\n",
    "- $gradapprox = \\frac{J^{+} - J^{-}}{2  \\varepsilon}$\n",
    "- Then compute the gradient using backward propagation, and store the result in a variable \"grad\"\n",
    "- Finally, compute the relative difference between \"gradapprox\" and the \"grad\" using the following formula: $$ difference = \\frac {\\mid\\mid grad - gradapprox \\mid\\mid_2}{\\mid\\mid grad \\mid\\mid_2 + \\mid\\mid gradapprox \\mid\\mid_2} \\tag{2}$$ You will need 3 Steps to compute this formula:\n",
    "- 1'. compute the numerator using np.linalg.norm(...)\n",
    "- 2'. compute the denominator. You will need to call np.linalg.norm(...) twice.\n",
    "- 3'. divide them.\n",
    "- If this difference is small (say less than $10^{-7}$), you can be quite confident that you have computed your gradient correctly. Otherwise, there may be a mistake in the gradient computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Gradient_check(x,theta,epsilon = 1e-7):\n",
    "    '''\n",
    "    Single number x:\n",
    "    ---------------\n",
    "    Implement the backward propagation present in Figure\n",
    "    Arguments:\n",
    "        theta_plus -------> θ+epsilon\n",
    "        theta_minus -------> θ-epsilon\n",
    "        J_plus ----------> input parameter \"theta_plus\" in forward propagation\n",
    "        gradapprox  -----------> approx by derivative's theta\n",
    "        \n",
    "    return difference between true derivative theta and approx theta\n",
    "    '''\n",
    "    \n",
    "    theta_plus = theta + epsilon\n",
    "    theta_minus = theta - epsilon\n",
    "    \n",
    "    J_plus = forward_propagation(x,theta_plus)\n",
    "    j_minus = forward_propagation(x,theta_minus)\n",
    "    gradapprox = (J_plus - j_minus) / (2 * epsilon)\n",
    "    \n",
    "    grad = backward_propagations(x)\n",
    "    numerator = np.linalg.norm(grad-gradapprox)\n",
    "    denominator = np.linalg.norm(grad) + np.linalg.norm(gradapprox)\n",
    "    \n",
    "    difference = numerator /denominator\n",
    "    \n",
    "    if difference < epsilon:\n",
    "        print('Perfect，The Gradient is current')\n",
    "    else:\n",
    "        print('The Gradient is wrong')\n",
    "    return difference\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perfect，The Gradient is current\n",
      "Difference =2.919335883291695e-10\n"
     ]
    }
   ],
   "source": [
    "difference = Gradient_check(2,4)\n",
    "print('Difference ={}'.format(difference))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Congrats, the difference is smaller than the $10^{-7}$ threshold. So you can have high confidence that you've correctly computed the gradient in backward_propagation().\n",
    "\n",
    "Now, in the more general case, your cost function $J$ has more than a single 1D input. When you are training a neural network, $\\theta$ actually consists of multiple matrices $W^{[l]}$ and biases $b^{[l]}$! It is important to know how to do a gradient check with higher-dimensional inputs. Let's do it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3) N-dimensional gradient checking\n",
    "The following figure describes the forward and backward propagation of your fraud detection model.\n",
    "![](../../picture/75.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### now, we create activation function\n",
    "- we use \"Relu\"\n",
    "- this is a 3 layer DNN, the L-dims = [4,5,3,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_check_n_test_case(): \n",
    "    np.random.seed(1)\n",
    "    x = np.random.randn(4,3)\n",
    "    y = np.array([1, 1, 0])\n",
    "    W1 = np.random.randn(5,4) \n",
    "    b1 = np.random.randn(5,1) \n",
    "    W2 = np.random.randn(3,5) \n",
    "    b2 = np.random.randn(3,1) \n",
    "    W3 = np.random.randn(1,3) \n",
    "    b3 = np.random.randn(1,1) \n",
    "    parameters = {\"W1\": W1,\n",
    "                  \"b1\": b1,\n",
    "                  \"W2\": W2,\n",
    "                  \"b2\": b2,\n",
    "                  \"W3\": W3,\n",
    "                  \"b3\": b3}\n",
    "\n",
    "    \n",
    "    return x, y, parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Relu(Z):\n",
    "    return np.maximum(0,Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(Z):\n",
    "    return 1. / (1 + np.exp(-Z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagation_n(X,Y,paramerts):\n",
    "    \n",
    "    '''\n",
    "    Implement forward propagation presented in Figure 3 \n",
    "    \n",
    "    '''\n",
    "    m = X.shape[1]\n",
    "    W1 = paramerts['W1']\n",
    "    b1 = paramerts['b1']\n",
    "    W2 = paramerts['W2']\n",
    "    b2 = paramerts['b2']\n",
    "    W3 = paramerts['W3']\n",
    "    b3 = paramerts['b3']\n",
    "    \n",
    "    Z1 = np.dot(W1,X) + b1\n",
    "    A1 = Relu(Z1)\n",
    "    Z2 = np.dot(W2,A1) + b2\n",
    "    A2 = Relu(Z2)\n",
    "    Z3 = np.dot(W3,A2) + b3\n",
    "    A3 = sigmoid(Z3)\n",
    "    \n",
    "     # Cost\n",
    "    logprobs = np.multiply(-np.log(A3),Y) + np.multiply(-np.log(1 - A3), 1 - Y)\n",
    "    cost = 1./m * np.sum(logprobs)\n",
    "    \n",
    "    cache = (Z1, A1, W1, b1, Z2, A2, W2, b2, Z3, A3, W3, b3)\n",
    "    \n",
    "    return cost, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_propagation_n(X,Y,cache):\n",
    "    '''\n",
    "    Implement backward propagation presented in Figure 3 \n",
    "    '''\n",
    "    \n",
    "    \n",
    "    Z1, A1, W1, b1, Z2, A2, W2, b2, Z3, A3, W3, b3 = cache\n",
    "    \n",
    "    m = X.shape[1]\n",
    "    # start backward propagation\n",
    "    \n",
    "    dZ3 = A3 - Y\n",
    "\n",
    "    dW3 = 1./m * np.dot(dZ3,A2.T)\n",
    "    db3 = 1./m * np.sum(dZ3,axis=1,keepdims=True)\n",
    "    \n",
    "    dA2 = np.dot(W3.T,dZ3)\n",
    "    dZ2 = np.multiply(dA2,np.int64(Z2 > 0))\n",
    "#     dW2 = 1./m * np.dot(dZ2,A1.T) \n",
    "    dW2 = np.dot(dZ2,A1.T)  # wrong code\n",
    "    db2 = 1./ m * np.sum(dZ2,axis=1,keepdims=True)\n",
    "    \n",
    "    dA1 = np.dot(W2.T,dZ2)\n",
    "    dZ1 = np.multiply(dA1,np.int64(Z1 > 0))\n",
    "    dW1 = 1./ m * np.dot(dZ1,X.T)\n",
    "#     db1 = 1./m * np.sum(dZ1,axis=1,keepdims=True)\n",
    "    db1 = 2./m * np.sum(dZ1,axis=1,keepdims=True) # wrong code\n",
    "\n",
    "    \n",
    "    \n",
    "    gradients = {'dZ3':dZ3,'dW3':dW3,'db3':db3,\n",
    "                'dZ2':dZ2,'dW2':dW2,'db2':db2,\n",
    "                 'dZ1':dZ1,'dW1':dW1,'db1':db1\n",
    "                } \n",
    "    return gradients\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### How does gradient checking work?.\n",
    "\n",
    "- As in 1) and 2), you want to compare \"gradapprox\" to the gradient computed by backpropagation. The formula is still:\n",
    "\n",
    "$$ \\frac{\\partial J}{\\partial \\theta} = \\lim_{\\varepsilon \\to 0} \\frac{J(\\theta + \\varepsilon) - J(\\theta - \\varepsilon)}{2 \\varepsilon} \\tag{1}$$\n",
    "- However, $\\theta$ is not a scalar anymore. It is a dictionary called \"parameters\". We implemented a function \"dictionary_to_vector()\" for you. It converts the \"parameters\" dictionary into a vector called \"values\", obtained by reshaping all parameters (W1, b1, W2, b2, W3, b3) into vectors and concatenating them.\n",
    "\n",
    "- The inverse function is \"vector_to_dictionary\" which outputs back the \"parameters\" dictionary.\n",
    "![](../../Picture/76.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instructions: Here is pseudo-code that will help you implement the gradient check.\n",
    "\n",
    "For each i in num_parameters:\n",
    "\n",
    "To compute J_plus[i]:\n",
    "- Set $\\theta^{+}$ to np.copy(parameters_values)\n",
    "- Set $\\theta^{+}_i$ to $\\theta^{+}_i + \\varepsilon$\n",
    "- Calculate $J^{+}_i$ using to forward_propagation_n(x, y, vector_to_dictionary($\\theta^{+}$ )).\n",
    "- To compute J_minus[i]: do the same thing with $\\theta^{-}$\n",
    "- Compute $gradapprox[i] = \\frac{J^{+}_i - J^{-}_i}{2 \\varepsilon}$\n",
    "- Thus, you get a vector gradapprox, where gradapprox[i] is an approximation of the gradient with respect to parameter_values[i]. You can now compare this gradapprox vector to the gradients vector from backpropagation. Just like for the 1D case (Steps 1', 2', 3'), compute: $$ difference = \\frac {\\| grad - gradapprox \\|_2}{\\| grad \\|_2 + \\| gradapprox \\|_2 } \\tag{3}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dictionary_to_Vector(parameters):\n",
    "    keys_ = []\n",
    "    theta_  = parameters['W1'].reshape(-1,1)\n",
    "    for keys in [ \"b1\", \"W2\", \"b2\", \"W3\", \"b3\"]:\n",
    "        # Then result is \"shape(x,),This is very scary !_!\" if use ravel() or flatten，so we use reshape(-1,1)\n",
    "        faltten_ = parameters[keys].reshape(-1,1)  \n",
    "        theta_ = np.concatenate((theta_,faltten_))\n",
    "        keys_ += [keys] * parameters[keys].shape[0] * parameters[keys].shape[1]\n",
    "    \n",
    "    \n",
    "      \n",
    "    return theta_,keys_\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradients_to_Vector(gradients):\n",
    "    keys_ = []\n",
    "    theta_ = gradients['dW1'].reshape(-1,1)\n",
    "    for keys in [ \"db1\", \"dW2\", \"db2\", \"dW3\", \"db3\"]:\n",
    "        faltten_ = gradients[keys].reshape(-1,1) # the same of above\n",
    "        theta_ = np.concatenate((theta_,faltten_))\n",
    "        keys_ += [keys] * gradients[keys].shape[0] * gradients[keys].shape[1]\n",
    "    \n",
    "    \n",
    "      \n",
    "    return theta_,keys_\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector_to_Dictionary(theta):\n",
    "    \"\"\"\n",
    "    Unroll all our parameters dictionary from a single vector satisfying our specific required shape.\n",
    "    \"\"\"\n",
    "    parameters = {}\n",
    "    parameters[\"W1\"] = theta[:20].reshape((5,4))\n",
    "    parameters[\"b1\"] = theta[20:25].reshape((5,1))\n",
    "    parameters[\"W2\"] = theta[25:40].reshape((3,5))\n",
    "    parameters[\"b2\"] = theta[40:43].reshape((3,1))\n",
    "    parameters[\"W3\"] = theta[43:46].reshape((1,3))\n",
    "    parameters[\"b3\"] = theta[46:47].reshape((1,1))\n",
    "\n",
    "    return parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_check_n(parameters,gradients,X,Y,epsilon = 1e-7):\n",
    "    '''\n",
    "    Implement Gradient Checking\n",
    "    \n",
    "    Argument:\n",
    "    ---------\n",
    "    parameters_values: parameters to Vector,this vector is very very big\n",
    "    keys_ : Vector consisting of key names\n",
    "    grad : result of backward propagation in vector\n",
    "    num_paramerters:number of parameters_values \n",
    "    J_plus : J(θ+), same as parameters_values dimensions\n",
    "    J_minus: J(θ-), same as above\n",
    "    gradapprox: approximately equal grad\n",
    "    \n",
    "    return difference by \"grad\" and \"gradapprox\"\n",
    "    '''\n",
    "    \n",
    "  \n",
    "    # first,we need to parameters to flatten  ----> dictionary to Vector\n",
    "    parameters_values,keys_ = dictionary_to_Vector(parameters)\n",
    "    grad,_ = gradients_to_Vector(gradients)\n",
    "    num_paramerters = parameters_values.shape[0]\n",
    "    J_plus = np.zeros(shape=(num_paramerters,1))\n",
    "    J_minus = np.zeros(shape=(num_paramerters,1))\n",
    "    gradapprox = np.zeros(shape=(num_paramerters,1))\n",
    "    \n",
    "                       \n",
    "    for i in range(num_paramerters):\n",
    "        '''\n",
    "        why we need copy in for loop ?\n",
    "            We need to ensure that only one θ is changed per loop.\n",
    "        '''\n",
    "        theta_plus = np.copy(parameters_values)\n",
    "        theta_plus[i,0] += epsilon\n",
    "        \n",
    "        J_plus[i],_ = forward_propagation_n(X,Y,vector_to_Dictionary(theta_plus))\n",
    "        \n",
    "        theta_minus = np.copy(parameters_values)\n",
    "        theta_minus[i,0] -= epsilon\n",
    "        \n",
    "        J_minus[i],_ = forward_propagation_n(X,Y,vector_to_Dictionary(theta_minus))\n",
    "        \n",
    "        gradapprox[i] = (J_plus[i] - J_minus[i])/(2. * epsilon)\n",
    "        \n",
    "    \n",
    "    numerator = np.linalg.norm(grad-gradapprox)\n",
    "    denominator = np.linalg.norm(grad) + np.linalg.norm(gradapprox)\n",
    "    \n",
    "    difference = numerator /denominator\n",
    "\n",
    "\n",
    "    if difference > 1e-7:\n",
    "        print('There is a mistake in the backward propagation! difference = {}'.format(difference))\n",
    "    else:\n",
    "        print('There is perfect in the backward propagation! difference = {}'.format(difference))\n",
    "        \n",
    "    return difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is a mistake in the backward propagation! difference = 0.313475336891879\n"
     ]
    }
   ],
   "source": [
    "X, Y, parameters = gradient_check_n_test_case()\n",
    "\n",
    "cost, cache = forward_propagation_n(X, Y, parameters)\n",
    "gradients = backward_propagation_n(X, Y, cache)\n",
    "difference = gradient_check_n(parameters, gradients, X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### we can see this result is very close to 1e-7, even though the code run \"if difference > 1e-7\",but this does prove that backward propagation is correct.\n",
    "- now, we try run wrong code in backward propagation(Hint:dW2,db1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is a mistake in the backward propagation! difference = 0.313475336891879\n"
     ]
    }
   ],
   "source": [
    "X, Y, parameters = gradient_check_n_test_case()\n",
    "\n",
    "cost, cache = forward_propagation_n(X, Y, parameters)\n",
    "gradients = backward_propagation_n(X, Y, cache)\n",
    "difference = gradient_check_n(parameters, gradients, X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "you can see this result is very large relative to 1e-7.\n",
    "so, next step you need check backward propagation,but you need ensure other code is correct!\n",
    "\n",
    "- relative error > 1e-2 usually means the gradient is probably wrong\n",
    "- 1e-2 > relative error > 1e-4 should make you feel uncomfortable\n",
    "- 1e-4 > relative error is usually okay for objectives with kinks. But if there are no kinks (e.g. use of tanh - - -nonlinearities and softmax), then 1e-4 is too high.\n",
    "- 1e-7 and less you should be happy.\n",
    "\n",
    "Also keep in mind that the deeper the network, the higher the relative errors will be. So if you are gradient checking the input data for a 10-layer network, a relative error of 1e-2 might be okay because the errors build up on the way. Conversely, an error of 1e-2 for a single differentiable function likely indicates incorrect gradient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note\n",
    "\n",
    "- Gradient Checking is slow! Approximating the gradient with $\\frac{\\partial J}{\\partial \\theta} \\approx  \\frac{J(\\theta + \\varepsilon) - J(\\theta - \\varepsilon)}{2 \\varepsilon}$ is computationally costly. For this reason, we don't run gradient checking at every iteration during training. Just a few times to check if the gradient is correct.\n",
    "- Don’t let the regularization overwhelm the data. It is often the case that a loss function is a sum of the data loss and the regularization loss (e.g. L2 penalty on weights). One danger to be aware of is that the regularization loss may overwhelm the data loss, in which case the gradients will be primarily coming from the regularization term (which usually has a much simpler gradient expression). This can mask an incorrect implementation of the data loss gradient. Therefore, it is recommended to turn off regularization and check the data loss alone first, and then the regularization term second and independently. One way to perform the latter is to hack the code to remove the data loss contribution. Another way is to increase the regularization strength so as to ensure that its effect is non-negligible in the gradient check, and that an incorrect implementation would be spotted.\n",
    "\n",
    "- Gradient checking verifies closeness between the gradients from backpropagation and the numerical approximation of the gradient (computed using forward propagation).\n",
    "- Gradient checking is slow, so we don't run it in every iteration of training. You would usually run it only to make sure your code is correct, then turn it off and use backprop for the actual learning process.\n",
    "\n",
    "> <span style=\"color:orange\">More Information:</span>[Stanford CNN](http://cs231n.github.io/neural-networks-3/#gradcheck)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
