{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OptimizationMethod(Theory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Mini-batch 梯度下降法\n",
    "\n",
    "机器学习是一个高度依赖经验的过程,并伴随着大量的迭代过程和选择很多的model,在数据量非常大的时候,深度神经网络的运算会变得非常慢,那么选择使用好的优化算法能够大大提高效率.\n",
    "\n",
    "**Batch vs. Mini-batch Gradient descent:**\n",
    "\n",
    "在之前使用的梯度下降法(batch Gradient descent),我们会将m个数据放样本在一个巨大的矩阵X中:\n",
    "$X=\\begin{bmatrix}x^{(1)}\\\\ x^{(2)}\\\\ ...\\\\ x^{(m)}\\\\ \\end{bmatrix}$,将标签放入一个Y向量内,$y=\\begin{bmatrix}\n",
    "y^{(1)}\\\\ \n",
    "y^{(2)}\\\\ \n",
    "...\\\\ \n",
    "y^{(m)}\\\\ \n",
    "\\end{bmatrix}$\n",
    "\n",
    "那么之前所用的向量化虽然能够加快我们的运算速度,但是对于m非常大的话,那么处理速度仍然缓慢,比如$m = 5,000,000$.当你使用普通梯度下降法的时候,你需要先处理完这五百万的样本才能是进行一次梯度下降法,所以想办法先让梯度下降法处理一部分,那么你的算法速度将会更快.\n",
    "\n",
    "你可以将训练集分割为小一点的子训练集(为了讲解方便,我们使用步长为1000),那么这些子训练集就是Mini-batch:\n",
    "\n",
    "我们使用$X^{\\{1\\}}$来代表第一部分的Mini-batch,我们使用$X^{\\{2\\}}$来代表第二部分的Mini-batch.\n",
    "\n",
    "$X^{\\{t\\}}$:代表每一部分的Mini-batch样本$t\\in (1-5000)$,shape is $(1000,n_x)$.\n",
    "\n",
    "$\\underset{(m,n)}{X} =\\underset{X^{\\{1\\}}}{\\underbrace{|x^{(1)},x^{(2)},x^{(3)},...,x^{(1000)}|}}\\underset{X^{\\{2\\}}}{\\underbrace{|x^{(1001)},x^{(1002)},x^{(1003)},...,x^{(2000)}|}}......\\underset{X^{\\{5000\\}}}{\\underbrace{|x^{(4001)},x^{(4002)},x^{(4003)},...,x^{(5000)}|}}$\n",
    "\n",
    "同样也对于Y这样处理:\n",
    "\n",
    "$\\underset{(m,n)}{y} =\\underset{y^{\\{1\\}}}{\\underbrace{|y^{(1)},y^{(2)},y^{(3)},...,y^{(1000)}|}}\\underset{y^{\\{2\\}}}{\\underbrace{|y^{(1001)},y^{(1002)},y^{(1003)},...,y^{(2000)}|}}......\\underset{y^{\\{5000\\}}}{\\underbrace{|y^{(4001)},y^{(4002)},y^{(4003)},...,y^{(5000)}|}}$\n",
    "\n",
    "$Y^{\\{t\\}}$:代表每一部分的Mini-batch标签$t\\in (1-5000)$,shape is $(1,1000)$.\n",
    "\n",
    "那么每一个$Mini-batch t:  X^{\\{t\\}},Y^{\\{t\\}}$,这就是1000个训练样本以及相应的输出"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mini-batch gradient descent：**\n",
    "\n",
    "\n",
    "for t = 1,2....5000:{\n",
    "\n",
    "forward propagation on $X^{\\{t\\}}$\n",
    "\n",
    "$Z^{[1]} = w^{[1]} X^{\\{t\\}} + b^{[1]}$\n",
    "\n",
    "$A^{[1]} = g^{[1]}(Z^{[1]})$\n",
    "\n",
    "......\n",
    "\n",
    "$Z^{[l]} = W^{[l]}A^{[l-1]} + b^{[l]}$\n",
    "\n",
    "$A^{[l]} = g^{[l]}(Z^{[l]})$\n",
    "\n",
    "every Mini-batch size is 1000\n",
    "\n",
    "cost function $J^{\\{t\\}} = \\frac{1}{1000} \\sigma_{i} L(\\hat{y^{(i)}},y^{(i)}) + \\frac{lambda}{(2*1000)}\\cdot \\sum (||w||_F)$\n",
    "\n",
    "Backward propagations compute gradients with respect to $J^{\\{t\\}}$\n",
    "\n",
    "$W^{[l]}:= W^{[l]} -\\alpha * dW^{[l]},b^{[l]} := b^{[l]} - \\alpha * db^{[l]}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以上称之为进行一代训练(1 epoch of training),意味着只训练了一遍,所以我们很明显的能够看到普通的(batch gradient descent) 一次只能做1个梯度,而(Mini-batch gradient descent)一次能做5000个梯度,最后你可能需要在最外层创建一个for loop or while loop来多次训练寻找最优参数收敛值.\n",
    "\n",
    "[PDF](../../PDFS/78.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Understanding mini-batch gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在batch gradient descent,每次迭代你都需要遍历整个训练集,在正确的情况下每次迭代的成本都应该会下降,如果某次成本函数J上升了.那么一定是某些地方出了错误,也许是你的学习率太大导致跑出了最优点,当然还肯能是别的原因.\n",
    "\n",
    "那么最好的形式应该如下图所示:\n",
    "\n",
    "<img width=500 height=500 src=\"../../picture/70.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用mini-batch梯度下降法,并不是每次迭代都是下降的,特别的,如果我们将每一步的J都绘制出来,也就是每次迭代下你的训练集都是不同的训练样本,或者说不同的mini-batch set,所以成本函数J虽然会朝下走,但是会伴随着很多的噪声,噪声产生的原因在于:\n",
    "\n",
    "也许某个$X^{\\{t\\}},Y^{\\{t\\}}$是比较容易学习的,因此成本会低一些,但是也可能由于某些$X^{\\{t\\}},Y^{\\{t\\}}$是比较难学习的那么成本就会高一些,注意噪声不一定就是坏处,因为含有噪声,因此会稍微减轻过拟合的程度.特别的,如果我们将每一步的J都绘制出来如下所示:\n",
    "\n",
    "<img width=500 height=500 src=\"../../picture/71.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ps:**\n",
    "\n",
    "> (1) 我们可以求每一个mini-batch的平均即$loss_{mean}= \\frac{J(mini-batch)}{num\\;batchs},\\;\\;num\\;batchs = \\frac{All\\;sample}{mini-batch \\;size}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Choose your mini-batch size:**\n",
    "\n",
    "极端情况下:\n",
    "\n",
    "if mini-batch size = m : Batch gradient descent $(X^{\\{1\\}},Y^{\\{1\\}}) = (X,Y)$.\n",
    "\n",
    "if mini-batch size = 1 : stochastic gradient descent(随机梯度下降法),then Every example is its own mini-batch   $(X^{\\{1\\}},Y^{\\{1\\}}) = (x^{(1)},y^{(1)}),(X^{\\{2\\}},Y^{\\{2\\}}) = (x^{(2)},y^{(2)})...$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在两个极端情况下成本函数的优化情况:\n",
    "\n",
    "(1) 对于batch gradient descent而言,噪声会相对低些,幅度也会大一些(蓝色代表).\n",
    "\n",
    "(2) 相反在stochastic gradient descent 而言,每次迭代只对一个mini-batch进行梯度下降,总体而言你会向着最小值靠近,但有时候你会远离最小值,那么就会导致方向错误,其实最后会在最小值范围波动,但是不会在最小值处停留(紫色部分).\n",
    "\n",
    "<img width=300 height=300 src=\"../../picture/72.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "所以正常而言,mini-batch size 应该选择在1-m之间,那么你既享受使用向量化所带来的加速,又不会在迭代计算成本函数上消耗太多时间,实际上mini-batch gradient descent的下降趋势会比stochastic gradient descent要快一些,但是最终也可能是围绕着最优值进行下降,但是此时你可以选择较小的学习率来缩小范围(图中绿色部分)\n",
    "\n",
    "**Ps:**\n",
    "\n",
    "> 使用batch gradient descent,当样本量太大的时候,那么每次迭代都需要大量的时间.\n",
    "\n",
    "> 使用stochastic gradient descent,虽然没有消耗大量时间(因为每次只有一个样本),但是弊端是你就丢失了向量化带来的加速,因为每次只计算一个样本,而我们使用向量化的目的就是一次计算多个样本而且在训练的过程会会极大肯能导致梯度方向的错误.\n",
    "\n",
    "> 现在我们一般都将使用mini-batch更新梯度就称之为SGD,且SGD可以依据改变mini-batch的达到不同的效果,比如mini-btahc=1,即为纯意义上的SGD,如果mini-btahc=batch,那么SGD就表示GD.\n",
    "\n",
    "\n",
    "\n",
    "最优值选择:\n",
    "\n",
    "- 如果训练样本较小(m <=2000),直接选择batch gradient descent.\n",
    "- 如果样本量大,mini-batch size: 64,512..\n",
    "  - 因为考虑到电脑内置，mini-batch 一般的大小是2的n次方\n",
    "- 确定你的$X^{\\{t\\}},Y^{\\{t\\}}$要符合你电脑的GPU/CPU的运行内存,如果不符合,那么你会发现算法的表现会急剧下降.\n",
    "- 实际上mini-batch 又是一个超级参数,你需要做一个尝试来选择最优的mini-batch来有效的减小成本函数,建议使用2的n次方进行尝试.\n",
    "\n",
    "**SGD和Mini-batch的缺点:**\n",
    "\n",
    "(1) Mini-batch gradient descent 不能保证很好的收敛性,learning rate 如果选择的太小,收敛速度会很慢,如果太大,loss function 就会在极小值处不停地震荡甚至偏离.(有一种措施是先设定大一点的学习率,当两次迭代之间的变化低于某个阈值后,就减小 learning rate,不过这个阈值的设定需要提前写好,这样的话就不能够适应数据集的特点.)对于非凸函数,还要避免陷于局部极小值处,或者鞍点(马鞍点)处,因为鞍点周围的error是一样的,所有维度的梯度都接近于0,会在鞍点或者局部最小点震荡跳动,另外,如果是训练集全集带入即BGD,则优化会停止不动,如果是mini-batch或者SGD,每次找到的梯度都是不同的,就会发生震荡,来回跳动.\n",
    "\n",
    "(2) SGD对所有参数更新时应用同样的 learning rate,如果我们的数据是稀疏的,我们更希望对出现频率低的特征进行大一点的更新.且LR会随着更新的次数逐渐变小.\n",
    "\n",
    "马鞍点:\n",
    "\n",
    "<img width=300 height=300 src=\"../../picture/78.png\" />\n",
    "\n",
    "广义而说,一个光滑函数(曲线,曲面,或超曲面)的鞍点邻域的曲线,曲面,或超曲面,都位于这点的切线的不同边.\n",
    "\n",
    "即上图所示,鞍点这词语来自于不定二次型 ${\\displaystyle x^{2}-y^{2}\\,}$的二维图形,像个马鞍:在x-轴方向往上曲,在y-轴方向往下曲.\n",
    "\n",
    "[PDF](../../PDFS/C2W2L02notes.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Exponential Moving Average(EMA,EXMA) 指数加权平均(指数加权移动平均)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在深度学习优化算法中,例如Momentum、RMSprop、Adam,都提到了一个概念--指数加权平均.\n",
    "\n",
    "指数加权平均也叫指数加权移动平均,通过它可以来计算局部的平均值,来描述数值的变化趋势,下面通过一个温度的例子来详细介绍一下.\n",
    "\n",
    "<img width=500 height=500 src=\"../../picture/73.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "其中横轴为天数,纵轴为温度($\\theta_i$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "那么使用我们以往的平均方式(100天)即为:\n",
    "\n",
    "$V_{aver}=\\frac{\\theta_1+\\theta_2+...+\\theta_{100}}{100}$,这样计算出来的值意味着每一个$\\theta_i$的权重均为$0.1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "那么我们现在来尝试一下使用局部平均值(移动平均值)EMA计算:\n",
    "\n",
    "<span style=\"color:orange\">其公式为:</span>$v_t =\\beta\\cdot v_{(t-1)} + (1-\\beta)\\cdot \\theta_t$\n",
    "\n",
    "公式中$θ_t$为t时刻的实际温度;系数 β 表示加权下降的快慢,值越小权重下降的越快;$v_t$ 为 t 时刻 EMA 的值."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "那么计算形式如下($\\beta=0.9$):\n",
    "\n",
    "$v_0=0$\n",
    "\n",
    "$v_1 = 0.9v_0 + 0.1\\theta_1$\n",
    "\n",
    "$v_2 = 0.9v_1 + 0.1\\theta_2$\n",
    "\n",
    "$v_3 = 0.9v_2 + 0.1\\theta_3$\n",
    "\n",
    "...\n",
    "\n",
    "$v_{100} = 0.9v_{99} + 0.1\\theta_{100}$\n",
    "\n",
    "[PDF](../../PDFS/C2W2L03notes.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 MEA的原理:\n",
    "\n",
    "<span style=\"color:orange\">实际上$v_t$只考虑了最近$\\frac{1}{1-\\beta}$天的数据来计算指数移动平均.</span>\n",
    "\n",
    "证明:\n",
    "\n",
    "当$\\beta=0.9$代表近似计算了$\\frac{1}{1-0.9}=10$天的数据来计算指数移动平均.\n",
    "\n",
    "$v_{100} = 0.9v_{99} + 0.1\\theta_{100}$\n",
    "\n",
    "$v_{99} = 0.9v_{98} + 0.1\\theta_{99}$\n",
    "\n",
    "$v_{98} = 0.9v_{97} + 0.1\\theta_{98}$\n",
    "\n",
    "$v_{97} = 0.9v_{96} + 0.1\\theta_{97}$\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将$v_{100}$展开:\n",
    "\n",
    "$v_{100} =0.1\\theta_{100}+0.9v_{99}  = 0.1\\theta_{100}+0.9(0.9(0.1\\theta_{99}+0.9v_{98}))$\n",
    "\n",
    "继续展开得到:\n",
    "\n",
    "$v_{100} =0.1\\theta_{100}+0.1*0.9\\theta_{99}+0.1*0.9^{2}\\theta_{98}+0.1*0.9^{3}\\theta_{97}+...+0.1*0.9^{99}\\theta_1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在指数移动平均中,当权重下降到$\\frac{1}{e},e=2.71828$时,后面的值基本可以小到不考虑.\n",
    "\n",
    "然而:\n",
    "\n",
    "$\\beta^{\\frac{1}{1-\\beta}}=0.9^{10}\\approx \\frac{1}{e}=0.36$\n",
    "\n",
    "可以看到第10天的时候基本上已经很小了,且后面会越来越小,可以忽略掉.\n",
    "\n",
    "所以为什么说$v_t$近似的计算了最近$\\frac{1}{1-\\beta}$天的指数移动平均.\n",
    "\n",
    "**Ps:**\n",
    "\n",
    "> 如果你想要计算10天局部温度的平均值,你需要保存最近10天的温度.使用指数加权平均来计算局部平均值的时候,可以节省大量的空间,你只需要保存前一个加权平均值.相对于直接计算平均值而言,它的精确度没有那么高.\n",
    "\n",
    "> 在算法中,我们一般取$\\beta>0.9$.\n",
    "\n",
    "> 其本质就是以指数式递减加权的移动平均,各数值的加权而随时间而指数式递减,越近期的数据加权越重,但较旧的数据也给予一定的加权.\n",
    "这就是指数加权平均的好处,可以进行更深度的分析一组数据的集中趋势,而普通均值每一项的权重都是一样的为$\\frac{1}{n}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们已经知道了$v_t$近似的计算了$\\frac{1}{1-\\beta}$天的指数移动平均.那么我们用图像的方式来看看指数加权移动平均的好处.\n",
    "\n",
    "当$\\beta=0.9$,意味着我们大约使用10天的数据一平均.\n",
    "\n",
    "<img width=500 height=500 src=\"../../picture/74.png\" />\n",
    "\n",
    "当$\\beta=0.98$,意味着我们大约使用50天的数据一平均.\n",
    "\n",
    "<img width=500 height=500 src=\"../../picture/75.png\" />\n",
    "\n",
    "当$\\beta=0.5$,意味着我们大约使用了2天的数据一平均.\n",
    "\n",
    "<img width=500 height=500 src=\"../../picture/76.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "绿线相对于红线来说,更加平稳、稳定.相对于红线来说缺点就是,它向右平移了,产生了延迟,因为当β为0.98时,相当于平均了$\\frac{1}{1-0.98}=50$天的温度,而β为0.9只是平均了10天的温度.\n",
    "\n",
    "黄线相对于红线和绿线来说,它抖动的更加厉害,因为它只平均了2天的温度,所以对于温度的趋势反馈能够更加的及时,更快的适应温度的变化,同时它也会带来更多的噪声(平均的天数太少).\n",
    "\n",
    "**可以看出红线的效果是最好的($\\beta=0.9$).**\n",
    "\n",
    "[PDF](../../PDFS/C2W2L04notes.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Bias correction in exponentially weighted average\n",
    "\n",
    "实际上,当我们执行$\\beta=0.98$的时候,得到的并不是绿色的线,而是下图紫色的线\n",
    "\n",
    "<img width=500 height=500 src=\"../../picture/77.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们来看看这是为什么?\n",
    "\n",
    "当计算移动平均数的时候初始化$v_0 = 0$,\n",
    "\n",
    "$v_1 = 0.98v_{0} + 0.02θ_{1} = 0.02 * 40 = 8$,因此第一天的估计会比真实值小很多\n",
    "\n",
    "$v_2 = 0.98v_1 + 0.02θ_2 =  0.98*0.02θ_1 + 0.02θ_2=1.764$,很明显的$v_2$小于θ_1和θ_2的均值,所以也不能很好的预估出前两天的温度,也就是说就是因为初始值0的存在,会使得初期的紫线会低于绿线.\n",
    "\n",
    "有一个很好的办法可以修改这一估计,那就是偏差修正(Bias correction):\n",
    "\n",
    "**Bias correction $v_t= \\frac{v_t}{1-\\beta^{t}} $**\n",
    "\n",
    "\n",
    "t为现在的天数,\n",
    "\n",
    "$t = 2$: $1-β^{t}$ = $1-(0.98)^{2}$= 0.0396,因此前两天的温度将变成\n",
    "\n",
    "$\\frac{v_2}{0.0396} = \\frac{ 0.98*0.02θ_1 + 0.02*θ_2}{0.0396}=44.54$,真实均值为$\\frac{40+49}{2}=44.5$\n",
    "\n",
    "那么可以看到经过除上偏差后,整体会变大.那么就修正了之前的$v_2$.\n",
    "\n",
    "**Ps:**\n",
    "\n",
    "> 另外你会发现随着t的增加,$β^t$将接近于0,因为β是一个小数,所以当t很大的时候,那么偏差修正将不起多大的作用,所以在t很大的时候,绿线和紫线重合.但是在最开始的阶段,偏差修正会更加帮助你精确预测.\n",
    "\n",
    "> 在机器学习中,在计算指数加权平均数的时候,大部分人不在乎初期的偏差修正,在熬过初期拿到最具有好的估测,然后在继续计算下去,但是如果你关心初期的偏差,那么你也可以使用偏差修正.\n",
    "\n",
    "[PDF](../../PDFS/C2W2L05notes.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizer\n",
    "\n",
    "\n",
    "### 3.1 Gradient descent with momentum动量梯度下降法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "假如你现在有一个要优化的成本函数:\n",
    "\n",
    "<img width=500 height=500 src=\"../../picture/79.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "红点代表最优值处\n",
    "\n",
    "我们在执行梯度下降法(batch or mini-batch)可能的走势(第一次迭代的w,b的值较小,w,b的更新梯度($w:w-\\alpha dw,b:b-\\alpha db$)就会较大,多次迭代后的梯度值就会变小)如下图所示,经过多次迭代慢慢的靠近最小值,如下图所示:\n",
    "\n",
    "\n",
    "<img width=500 height=500 src=\"../../picture/80.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这种上下波动,实际上会减慢了梯度下降法的速度,另外如果你使用较大的学习率,那么摆动幅度可能会更大,导致偏离了函数的范围:\n",
    "\n",
    "<img width=500 height=500 src=\"../../picture/81.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "因此在纵轴上,你希望学习慢一点(因为学习率太大会偏离函数范围),但是在横轴上你希望加快学习速度(快速从左到右移动到最小值).\n",
    "\n",
    "那么使用momentum就可以解决,然而你需要做的就是:\n",
    "\n",
    "Ng给出的形式如下:\n",
    "\n",
    "Initialization $v_{dw}=0,v_{db}=0$\n",
    "\n",
    "On iteration t:\n",
    "\n",
    "Compute dw,db on the current mini-batch\n",
    "\n",
    "$v_{dw} = \\beta v_{dw} + (1-\\beta)dW$\n",
    "\n",
    "$v_{db} = \\beta v_{db} + (1-\\beta)db$\n",
    "\n",
    "$w:=w-\\alpha v_{dw},b:=b-\\alpha v_{db}$\n",
    "\n",
    "Hyperparameters: $\\alpha,\\beta$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "比如$\\beta=0.98$,那么就可以减缓梯度在纵轴方向上的振动(红色):\n",
    "\n",
    "<img width=500 height=500 src=\"../../picture/82.png\" />\n",
    "\n",
    "可以回顾一下在温度的例子中$\\beta=0.98$所带来的效果,即类似于红色的走势"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用一个小例子来理解momentum的本质:\n",
    "\n",
    "我们都知道末速度公式为:$V_t＝V_0+at$\n",
    "\n",
    "我们的成本函数是一个碗状的形状(底处最低点就是最优值),想象一下一个小球从上往下滚,那么对于 $dw,db$就相当于提供了加速度,而$V_{dw}，V_{db}$就相当于速度,而β就相当于给予了摩擦力(因为让加速度$dw,db$整体变小了),所以不会无限制的加速下去,于是梯度方向不变的维度上速度变快,梯度方向有所改变的维度上的更新速度变慢,这样就可以加快收敛并减小震荡.\n",
    "\n",
    "或者可以这样考虑(在二维情况下):\n",
    "\n",
    "momentum在更新参数时,也考虑了上一次的结果,比如上次更新时是往前走的,这次更新的梯度算出来是往左走,这变化太剧烈了,所以我们来做个折中,往左前方走.感觉上像是上次更新还带有一定的惯性.\n",
    "\n",
    "\n",
    "实际上momentum Gradient Descent有三种形式:\n",
    "\n",
    "(1) Ng形式:\n",
    "\n",
    "$v_{dw} = \\beta v_{dw} + (1-\\beta)dW$\n",
    "\n",
    "$v_{db} = \\beta v_{db} + (1-\\beta)db$\n",
    "\n",
    "$w:=w-\\alpha v_{dw},b:=b-\\alpha v_{db}$\n",
    "\n",
    "(2) [Pytorch](https://pytorch.org/docs/stable/optim.html#torch.optim.SGD),[Tensorflow](https://www.tensorflow.org/api_docs/python/tf/train/MomentumOptimizer?hl=en),Hinton大神给出的形式:\n",
    "\n",
    "(2.1) Pytorch Momentum\n",
    "\n",
    "<img width=500 height=500 src=\"../../picture/104.png\" />\n",
    "\n",
    "(2.2) Tensorflow Momentum\n",
    "\n",
    "<img width=500 height=500 src=\"../../picture/105.png\" />\n",
    "\n",
    "实际上这两个框架定义的形式和Ng给出的形式和这个很像(删除了$(1-\\beta)$),那么$v_{dw}$就相当于近似缩小了(1-β)倍,所以在最后$\\alpha$也会受到影响,实际上两个方法效果都还不错,只是会影响$\\alpha$的最佳值(因为$v_{dw}$的倍数减少)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(2.3) 根据论文[An overview of gradient descent optimization algorithms](https://arxiv.org/pdf/1609.04747.pdf)给出的形式,\n",
    "\n",
    "<img width=300 height=300 src=\"../../picture/99.png\" />\n",
    "\n",
    "\n",
    "实际上这种方式是与上面相似的,只是会少一个Learning rate倍数.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(3) 另外一种形式是依照原论文[On the importance of initialization and momentum in deep learning](http://www.cs.toronto.edu/~hinton/absps/momentum.pdf)给出的,在《DeepLearning》一书中也是采用这个形式.\n",
    "\n",
    "<img width=300 height=300 src=\"../../picture/98.png\" />\n",
    "\n",
    "《DeepLearning》书中给出的算法流程\n",
    "\n",
    "<img width=500 height=500 src=\"../../picture/95.png\" />\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(3.1) Keras Momentum\n",
    "\n",
    "<img width=500 height=500 src=\"../../picture/106.png\" />\n",
    "\n",
    "(3.2) CS231n\n",
    "\n",
    "<img width=500 height=500 src=\"../../picture/107.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "所以实际上采取什么方式都是可以的,Hinton给出的版本与TensorFlow这个是一样的,可以根据自己的喜好选择,我这里就使用和Tensorflow一样的形式."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ps:**\n",
    "\n",
    "- 动量参数一般为0.9左右\n",
    "\n",
    "- 缺点:这种情况相当于小球从山上滚下来时是在盲目地沿着坡滚,如果它能具备一些先知,比如提前知道了方向即将发生剧烈变化,先做好降速这样就更好了.\n",
    "\n",
    "[PDF](../../PDFS/C2W2L06lecture.pdf)\n",
    "\n",
    "**momentum reference:** Two problems with backpropagation and other steepest-descent learning procedures for networks. Proc. 8th Annual Conf. Cognitive Science Society. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Nesterov Accelerated Gradient\n",
    "\n",
    "\n",
    "在原论文[On the importance of initialization and momentum in deep learning](http://www.cs.toronto.edu/~hinton/absps/momentum.pdf)用$\\theta+\\beta v_{t−1}$来近似当做参数下一步会变成的值,则在计算梯度时,不是在当前位置,而是未来的位置上.\n",
    "\n",
    "<img width=300 height=300 src=\"../../picture/100.png\" />\n",
    "\n",
    "在《DeepLearning》书中给出的算法如下:\n",
    "\n",
    "<img width=500 height=500 src=\"../../picture/94.png\" />\n",
    "\n",
    "该优化器相对于Momentum,唯一不同的是计算梯度的时机,Momentum计算的是当前位置的梯度,Nesterov Momentum计算的是按照上次更新方向走一小步后的梯度."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "比较效果:\n",
    "\n",
    "<img width=500 height=500 src=\"../../picture/83.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "蓝色是Momentum的过程,会先计算当前的梯度,然后在更新后的累积梯度后会有一个大的跳跃,而NAG会先在前一步的累积梯度上(brown vector)有一个大的跳跃然后衡量一下梯度做一下修正(red vector),这种预期的更新可以避免我们走的太快.\n",
    "\n",
    "或者可以理解为:\n",
    "\n",
    "上次是往前走了10米,这次我先往前走上2米,然后再来观察下一步怎么走.可以认为是分两步更新了$\\theta$.\n",
    "\n",
    "但是如果依照原文(《DeepLearning》)的算法去实现Nesterov Accelerated Gradient会发现速度会非常的慢,主要原因就是下图红色框起来的部分:\n",
    "\n",
    "<img width=500 height=500 src=\"../../picture/101.png\" />\n",
    "\n",
    "红色部分表示我们需要在走一次Forward Propagation和Backward Propagation,这样的话速度就会慢两倍.现实运行下我们不会使用这个版本而是使用衍生版本.\n",
    "\n",
    "[1] [Keras](https://github.com/keras-team/keras/blob/master/keras/optimizers.py#L157)\n",
    "\n",
    "<img width=300 height=300 src=\"../../picture/108.png\" />\n",
    "\n",
    "[2] [CS231n](http://cs231n.github.io/neural-networks-3/)\n",
    "\n",
    "<img width=500 height=500 src=\"../../picture/103.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "实际上这两个都是走的一条公式(将所有式子依次带入):\n",
    "\n",
    "$\\theta=\\theta+\\beta^{2}V-(1+\\beta)\\alpha*g$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "细心的朋友会发现这种形式与《DeepLearning》和原论文给出的形式完全不一样,下面推导一下:\n",
    "\n",
    "原始公式:\n",
    "\n",
    "$V_{t+1}=\\beta V_{t}-\\alpha \\bigtriangledown_{\\theta_{t}}J(\\theta_{t}+\\beta V_t)$\n",
    "\n",
    "$\\theta_{t+1}=\\theta_{t}+V_{t+1}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们令:\n",
    "\n",
    "$\\theta^{'}_{t}=\\theta_{t}+\\beta V_t$\n",
    "\n",
    "则:\n",
    "\n",
    "$V_{t+1}=\\beta V_{t}-\\alpha \\bigtriangledown_{\\theta_{t}}J(\\theta^{'}_{t})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "那么:\n",
    "\n",
    "$\\theta^{'}_{t+1}=\\theta_{t+1}+\\beta V_{t+1}$\n",
    "\n",
    "$=\\theta_{t}+V_{t+1}+\\beta V_{t+1}$\n",
    "\n",
    "$=\\theta_{t}+(1+\\beta)V_{t+1}$\n",
    "\n",
    "$=\\theta^{'}_{t}-\\beta V_{t}+(1+\\beta)[\\beta V_{t}-\\alpha \\bigtriangledown_{\\theta^{'}_{t}}J(\\theta^{'}_{t})]$\n",
    "\n",
    "$=\\theta^{'}_{t}+\\beta^{2}V_t−(1+\\beta)\\alpha\\bigtriangledown_{\\theta^{'}_{t}}J(\\theta^{'}_{t})$\n",
    "\n",
    "下面替换回来,令 $\\theta_t=\\theta^{'}_t$,则上述公式为:\n",
    "\n",
    "$\\theta_{t+1}=\\theta_{t}+\\beta^{2}V-(1+\\beta)\\alpha\\bigtriangledown_{\\theta_{t}}J(\\theta_{t})$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这样写的好处是我们没有必要再计算$\\triangledown_{\\tilde{\\theta}}\\sum_{i}L(f(x^{(i)};\\tilde{\\theta}),y^{(i)}) $了,大大缩短了运行时间"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我这里使用Keras的形式\n",
    "\n",
    "则Nesterov的整体形式为:\n",
    "\n",
    "\n",
    "$V_{t+1} = \\beta V_{t} -\\alpha g$\n",
    "\n",
    "$\\theta_{t+1}=\\theta_{t}+\\beta V_{t+1}-\\alpha g$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NAG 可以使 RNN 在很多任务上有更好的表现.\n",
    "\n",
    "\n",
    "到现在为止,我们已经可以做到loss function在纵轴上振幅减少,在横轴上也不要速度太快的横冲直撞,另外我们还希望可以根据参数的重要性而对不同的参数进行不同程度的更新.\n",
    "\n",
    "**Ps:**\n",
    "- 动量参数一般选择0.9左右.\n",
    "- 实际上还有Pytorch版本的,但是看的不是很懂.\n",
    "\n",
    "Nesterov Accelerated paper:A method for unconstrained convex minimization problem with the rate of convergence o(1/k2). Doklady ANSSSR (translated as Soviet.Math.Docl.), vol. 269, pp. 543– 547.\n",
    "[Nesterov accelerated gradient (NAG)](https://blog.csdn.net/tsyccnh/article/details/76673073)\n",
    "\n",
    "---------\n",
    "\n",
    "目前为止,我们可以做到在更新梯度时顺应 loss function 的梯度来调整速度,并且对SGD进行加速.\n",
    "\n",
    "我们还希望可以根据参数的重要性而对不同的参数进行不同程度的更新."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Adagrad (Adaptive gradient algorithm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这个算法就可以对低频的参数做较大的更新,对高频的做较小的更新,也因此,对于稀疏的数据它的表现很好,很好地提高了SGD的鲁棒性(Robustness)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "梯度更新规则:\n",
    "\n",
    "### $\\theta_{t+1,i}=\\theta_{t,i}-\\frac{\\eta}{\\sqrt{G_{t,ii}+\\epsilon}}\\cdot g_{t,i}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里的$\\theta=\\{w,b\\}$,\n",
    "\n",
    "其中$g$为:t时刻参数$θ_i$的梯度:\n",
    "\n",
    "$g_{t,i}=\\triangledown_{\\theta}J(\\theta_i)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$G_{t,ii}$为一个对角阵$G_{t,ii}=G_{t,ii}+g_{t,i}\\cdot g_{t,i}^{T}$\n",
    "\n",
    "$\\epsilon$一般取$1e^{-8}$\n",
    "\n",
    "《DeepLearning》书中给出的算法\n",
    "\n",
    "<img width=500 height=500 src=\"../../picture/93.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "特殊之处在于这个递减系数由之前所有更新的梯度的平方的和来决定,可见,AdaGrad的学习率始终是在减小.\n",
    "\n",
    "它的优点在于,当$\\theta$是某个具体参数时,可以发现,这样计算学习率递减系数相当于:\n",
    "\n",
    "如果某个参数在这一步中梯度非常大($G_{t,ii}$大),那么这一步中学习率衰减就要大一些,好比坡太陡,往下走时必须小步走,步子一大就滚下去了.如果某个参数在这一步中梯度非常小,那么,这一步中学习率衰减就小一些,可以大步走.也就是说Adagrad的优点是减少了学习率的手动调节(会自动进行调节).但是在《DeepLearning》书中提到该OPtimizer在神经网络结构中会过早过量的减少学习率.\n",
    "\n",
    "在An overview of gradient descent optimization algorithms中$G_{t,ii}$是一个对角阵,但是在实际操作的时候,我们只需要$A\\odot A$,意味着Element-wise product.\n",
    "\n",
    "[Keras](https://github.com/keras-team/keras/blob/master/keras/optimizers.py#L288)的Adagrad:\n",
    "\n",
    "<img width=500 height=500 src=\"../../picture/114.png\" />\n",
    "\n",
    "[Pytorch](https://pytorch.org/docs/stable/_modules/torch/optim/adagrad.html#Adagrad)\n",
    "\n",
    "<img width=500 height=500 src=\"../../picture/115.png\" />\n",
    "\n",
    "所以我们给予一下算法:\n",
    "\n",
    "$G_{\\theta}=G_{\\theta}+(g)^2$\n",
    "\n",
    "$\\theta = \\theta - \\frac{\\alpha}{\\sqrt{G_{\\theta}}+\\epsilon}\\cdot g$\n",
    "\n",
    "**Ps:**\n",
    "> 缺点:衰减系数累积了所有更新步骤中的梯度,分母会不断积累,这样学习率就会收缩并最终会变得非常小,于是我们可能更希望考察最近几步中的梯度来决定衰减系数.\n",
    "\n",
    "> 对于学习率的选取一般取:0.01,$\\epsilon$一般选取$10^{-7}$\n",
    "\n",
    "[Adagrad paper](http://www.jmlr.org/papers/volume12/duchi11a/duchi11a.pdf)\n",
    "\n",
    "------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Adadelta\n",
    "AdaDelta算法也针对AdaGrad算法在迭代后期可能较难找到有用解的问题做了改进.有意思的是,AdaDelta算法没有学习率这一超参数(主要是因为经过近似牛顿迭代法之后得到的结果)\n",
    "\n",
    "这个算法是对 Adagrad 的改进和Adagrad相比,就是分母的$G$换成了过去的梯度平方的衰减平均值,**指数衰减平均值.**\n",
    "\n",
    "$RMS[g]_t=\\sqrt{E[g]^{2}_t+\\epsilon}$\n",
    "\n",
    "$E[g^{2}]_t = \\rho E[g^{2}]_{t-1}+(1-\\rho )g^{2}_{t}$\n",
    "\n",
    "\n",
    "那么:\n",
    "\n",
    "$t$时刻的依赖于前某时刻的平均和当前的梯度,比如$\\rho$=0.9,表示累积了前10个梯度,而不是目前所有的梯度\n",
    "\n",
    "原文论[Adadelta paper](https://arxiv.org/pdf/1212.5701.pdf)给出的算法流程:\n",
    "\n",
    "<img width=500 height=500 src=\"../../picture/109.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "其中:\n",
    "\n",
    "$E[g^{2}]_t = \\rho E[g^{2}]_{t-1}+(1-\\rho )g^{2}_{t}$\n",
    "\n",
    "$RMS[g]_t=\\sqrt{E[g]^{2}_t+\\epsilon}$\n",
    "\n",
    "$\\epsilon$通常取$10^{-6}$\n",
    "\n",
    "<span style=\"color:orange\">尽管算法原文不用使用学习率,但是Keras框架还是使用了默认学习率为1.0(也就是不使用额外的学习率),个人理解是为了控制衰减的程度,因为Adagrad实际上在神经网络中可能会过早的衰减学习率,虽然Adadelta具有一定优化作用,但是如果完全不使用学习率也是无法保证在所有情况下都是优秀的,所以Keras加入学习率来控制Adadelta的衰减程度.</span>\n",
    "\n",
    "[Keras](https://github.com/keras-team/keras/blob/master/keras/optimizers.py#L353):\n",
    "\n",
    "<img width=500 height=500 src=\"../../picture/110.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "有趣的是,Keras并没有采用统计意义上的RMS:将所有值平方求和,求其均值,再开平方,就得到均方根值,所以可以用[root mean square(RMS)](https://zh.wikipedia.org/wiki/%E5%B9%B3%E6%96%B9%E5%B9%B3%E5%9D%87%E6%95%B0)表示.\n",
    "\n",
    "Keras中的a是直接由0初始化来的\n",
    "<img width=500 height=500 src=\"../../picture/111.png\" />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "所以我们可以给出如下算法过程:\n",
    "\n",
    "$S_{dw}=\\rho S_{dw} +(1-\\rho)({dw})^{2}$\n",
    "\n",
    "$S_{db}=\\rho S_{db} +(1-\\rho)({db})^{2}$\n",
    "\n",
    "$V_{dw}=\\frac{\\sqrt{\\triangledown_{w}+\\epsilon}}{\\sqrt{S_{dw}+\\epsilon}}\\cdot dw$\n",
    "\n",
    "$V_{db}=\\frac{\\sqrt{\\triangledown_{b}+\\epsilon}}{\\sqrt{S_{db}+\\epsilon}}\\cdot db$\n",
    "\n",
    "$w=w-lr*V_{dw}$\n",
    "\n",
    "$b = b -lr*V_{db}$\n",
    "\n",
    "$\\triangledown_{w} = \\rho \\triangledown_{w} + (1-\\rho)(V_{dw})^{2}$\n",
    "\n",
    "$\\triangledown_{b} = \\rho \\triangledown_{b} + (1-\\rho)(V_{db})^{2}$\n",
    "\n",
    "其中这里的$lr$是可以乘(Keras)也可以不乘(原文),$\\rho=0.9$\n",
    "\n",
    "\n",
    "------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5  RMSprop\n",
    "\n",
    "RMSprop 是 Geoff Hinton 提出的一种自适应学习率方法,RMSprop 和 Adadelta 都是为了解决 Adagrad 学习率急剧下降问题的以在非凸的情况下效果更好.Hinton大佬提出这个算法是在[PPT讲解](https://www.cs.toronto.edu/~tijmen/csc321/slides/lecture_slides_lec6.pdf)的时候提出的,并没有以论文的形式发表.\n",
    "\n",
    "给定超参数 $0≤\\boldsymbol{p}<1$,RMSProp算法在时间步 $t>0$ 计算:\n",
    "\n",
    "$\\boldsymbol{r}_{t}=\\boldsymbol{p}\\boldsymbol{r}_{t-1}+(1−\\boldsymbol{p})g_t⊙g_t.$\n",
    "\n",
    "$\\theta_{t}=\\theta_{t-1}-\\frac{\\eta}{\\sqrt{\\boldsymbol{r_{t}}+\\epsilon}}⊙g_t$\n",
    "\n",
    "其中$\\eta$是学习率,$⊙$逐个元素相乘,$\\epsilon$是为了维持数值稳定性而添加的常数,如$10^{-6}$.因为RMSProp算法的状态变量 $\\boldsymbol{r}_{t}$是对平方项 $gt⊙gt$ 的指数加权移动平均,所以可以看作是最近$\\frac{1}{1-\\boldsymbol{p}}$个时间步的小批量随机梯度平方项的加权平均.如此一来,自变量每个元素的学习率在迭代过程中就不再一直降低(或不变).\n",
    "\n",
    "使用的是指数加权平均,旨在消除梯度下降中的摆动,与Momentum的效果一样,分母的衰减部分和Adagrad的思想是样的,如果导数梯度较大,则衰减较大,整体的更新比较小,好比非常陡的坡要小步走,走大了容易滚下去.反之衰减较小.\n",
    "\n",
    "也就是说:\n",
    "\n",
    "<span style=\"color:orange\">某一维度的导数比较大,则指数加权平均就大,某一维度的导数比较小,则其指数加权平均就小,这样就保证了各维度导数都在一个量级,进而减少了摆动.而且允许使用一个更大的学习率$\\eta$.</span>\n",
    "\n",
    "《DeepLearning》中给出的算法流程\n",
    "\n",
    "<img width=500 height=500 src=\"../../picture/96.png\" />\n",
    "\n",
    "在[Keras](https://github.com/keras-team/keras/blob/master/keras/optimizers.py#L220)和Ng给出的形式都是一样的\n",
    "\n",
    "<img width=500 height=500 src=\"../../picture/112.png\" />\n",
    "\n",
    "\n",
    "所以我们定义的算法为:\n",
    "\n",
    "$S_{dW}=\\beta S_{dW} + (1-\\beta)({dW})^2$\n",
    "\n",
    "$S_{db}=\\beta S_{db} + (1-\\beta)({db})^2$\n",
    "\n",
    "$W = W -\\alpha \\frac{dW}{\\sqrt{S_{dW}+\\epsilon}}$\n",
    "\n",
    "$b = b -\\alpha \\frac{db}{\\sqrt{S_{db}+\\epsilon}}$\n",
    "\n",
    "**Ps:**\n",
    "> Hinton建议Learning rate:$0.001$,momentum:$\\beta=0.9$,而且我们的$\\epsilon$可以取值为$10^{-6}$\n",
    "\n",
    "> 适合处理非平稳目标,在Keras中是这样写道的:这个优化器通常是训练循环神经网络RNN的不错选择\n",
    "\n",
    "\n",
    "另外附上:RMSProp + Nesterov momentum 算法\n",
    "\n",
    "<img width=500 height=500 src=\"../../picture/97.png\" />\n",
    "\n",
    "[PDF](../../PDFS/C2W2L07notes.pdf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6 Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这个算法是另一种计算每个参数的自适应学习率的方法.相当于 RMSprop + Momentum\n",
    "\n",
    "除了像 Adadelta 和 RMSprop 一样存储了过去梯度的平方 $v_t$ 的指数衰减平均值,也像 momentum 一样保持了过去梯度 $m_t$ 的指数衰减平均值:\n",
    "\n",
    "$m_{t}=\\beta_{1}m_{t-1}+(1-\\beta_{1})g_{t}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$v_t=\\beta_{2}v_{t-1}+(1-\\beta_2)g^{2}_t$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果 $m_t$ 和 $v_t$ 被初始化为0向量,那它们就会向0偏置,所以做了偏差校正,通过计算偏差校正后的 $m_t$ 和 $v_t$ 来抵消这些偏差:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\widehat{m_t}=\\frac{m_t}{1-\\beta_{1}^{t}}$\n",
    "\n",
    "$\\widehat{v_t}=\\frac{v_t}{1-\\beta_{2}^{t}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "梯度更新规则:\n",
    "\n",
    "$\\theta_{t+1}=\\theta_{t}-\\frac{\\eta}{\\sqrt{\\widehat{v_t}+\\epsilon}}\\cdot\\widehat{m_t}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "超参数设定值:\n",
    "\n",
    "建议 $β_1 ＝ 0.9,β_2 ＝ 0.999,ϵ ＝ 10e−8$\n",
    "\n",
    "实践表明,Adam 比其他适应性学习方法效果要好.\n",
    "\n",
    "**Adam algorithm:**\n",
    "\n",
    "<img width=500 height=500 src=\"../../picture/86.png\" />\n",
    "\n",
    "\n",
    "[PDF](../../PDFS/C2W2L08notes.pdf)\n",
    "\n",
    "[Adam paper](https://arxiv.org/pdf/1412.6980.pdf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6 效果比较\n",
    "\n",
    "<img width=500 height=500 src=\"../../picture/84.gif\" />\n",
    "\n",
    "<img width=500 height=500 src=\"../../picture/85.gif\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上面两种情况都可以看出,Adagrad,Adadelta,RMSprop几乎很快就找到了正确的方向并前进,收敛速度也相当快,而其它方法要么很慢,要么走了很多弯路才找到.\n",
    "\n",
    "由图可知自适应学习率方法即 Adagrad, Adadelta, RMSprop, Adam 在这种情景下会更合适而且收敛性更好."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.7 如何选择Optimizer\n",
    "\n",
    "如果数据是稀疏的,就用自适用方法,即 Adagrad, Adadelta, RMSprop, Adam.\n",
    "\n",
    "RMSprop, Adadelta, Adam 在很多情况下的效果是相似的.\n",
    "\n",
    "Adam 就是在 RMSprop 的基础上加了 bias-correction 和 momentum.\n",
    "\n",
    "随着梯度变的稀疏,Adam 比 RMSprop 效果会好.\n",
    "\n",
    "整体来讲,Adam 是最好的选择."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reference:**\n",
    "\n",
    "[1] [优化器算法详解](http://www.cnblogs.com/guoyaohua/p/8542554.html)\n",
    "\n",
    "[2] [机器学习面试之各种优化器的比较](https://www.jianshu.com/p/ee39eca29117)\n",
    "\n",
    "[3] [An overview of gradient descent optimization algorithms](https://arxiv.org/pdf/1609.04747.pdf)\n",
    "\n",
    "[3.1] [An overview of gradient descent optimization algorithms](http://ruder.io/optimizing-gradient-descent/index.html)\n",
    "\n",
    "[4] [深度学习中优化方法](https://blog.csdn.net/u012328159/article/details/80311892)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 Learning rate decay\n",
    "\n",
    "加快学习的一个办法就是随着时间慢慢减少学习率,实际上在上面的Optimizer中具有自适应方法的比如Adagrad, Adadelta, RMSprop, Adam在迭代的过程中都在learning rate decay.\n",
    "\n",
    "首先举一个例子来看下为什么要有学习率衰减:\n",
    "\n",
    "在使用mini-batch的过程中因为会有很多噪声产生,但是整体最朝着最优值的方向进行,最终在最优值的周围摆动(这是因为你的学习率α是固定的)\n",
    "\n",
    "<img width=500 height=500 src=\"../../picture/87.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "但是如果慢慢的减少学习率α的话,在最初α还是较大的情况下,学习相对较快,但是随着迭代的次数,α会逐渐减小,更新的步长也会逐渐减小,最终会缩小最优值的范围摆动\n",
    "\n",
    "<img width=500 height=500 src=\"../../picture/88.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "学习率衰减方式:\n",
    "\n",
    "在每一个epoch下:\n",
    "\n",
    "(1) epoch衰减:$\\alpha = \\frac{1}{1+decay-rate*eoch-number}\\cdot \\alpha_0$,那么随着迭代次数的增加,学习率将下降.\n",
    "\n",
    "其中decay-rate为一个hyper parameter.\n",
    "\n",
    "(2) 指数衰减:$\\alpha=( K^ {epoch} ) * \\alpha_{0} $ K<0,maybe 0.95\n",
    "\n",
    "(3) 分式衰减: $\\alpha =(  \\frac{K}{{epoch-number}^{2}} ) * \\alpha_0 \\;or \\;(\\frac{K}{t^2} )* α_0 $\n",
    "\n",
    "t: mini-batch‘s t \n",
    "\n",
    "(4) 离散衰减,每个epoch减去一个常数\n",
    "\n",
    "(5) 手动衰减"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[PDF](../../PDFS/C2W2L09notes.pdf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
