{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Input,Dense\n",
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from miniBatch import random_mini_batche  \n",
    "from data_utils import get_CIFAR10_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data\n",
    "\n",
    "#train set: 2000 \n",
    "\n",
    "#val set: 100\n",
    "\n",
    "#test set: 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:  (49000, 3, 32, 32)\n",
      "y_train:  (49000,)\n",
      "X_val:  (1000, 3, 32, 32)\n",
      "y_val:  (1000,)\n",
      "X_test:  (1000, 3, 32, 32)\n",
      "y_test:  (1000,)\n"
     ]
    }
   ],
   "source": [
    "# Load the (preprocessed) CIFAR10 data.\n",
    "data = get_CIFAR10_data()\n",
    "for k, v in data.items():\n",
    "    print('%s: ' % k, v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(index_train,index_val,index_test):\n",
    "    \"\"\"\n",
    "    Load data set\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "       index_train: training set index range.\n",
    "       index_val: val data set index range.\n",
    "       index_test : test data set index range.\n",
    "    \n",
    "    Returns:\n",
    "    -------\n",
    "       train_x: train set data\n",
    "       train_y train set labels\n",
    "       val_x: val set data\n",
    "       val_y: val set labels\n",
    "       test_x: test set data\n",
    "       test_y: test set labels.\n",
    "    \"\"\"\n",
    "    train_x = data['X_train'][:index_train].reshape(index_train,-1)\n",
    "    train_y = data['y_train'][:index_train]\n",
    "    \n",
    "    val_x = data['X_val'][:index_val].reshape(index_val,-1)\n",
    "    val_y = data['y_val'][:index_val]\n",
    "    \n",
    "    test_x = data['X_test'][:index_test].reshape(index_test,-1)\n",
    "    test_y = data['y_test'][:index_test]\n",
    "    \n",
    "    return train_x,train_y,val_x,val_y,test_x,test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x,train_y,val_x,val_y,test_x,test_y = load_data(2000,100,100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/45947111/how-to-specify-the-axis-when-using-the-softmax-activation-in-a-keras-layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Keras of BN and BL\n",
    "\n",
    "函数解释:\n",
    "\n",
    "(1)\n",
    "\n",
    "```python\n",
    "def __init__(self,layers,mode,epochs,lr,batch_size,fielname):\n",
    "    ...```\n",
    "    \n",
    "该函数做预备初始化作用.\n",
    "\n",
    "\n",
    "    \n",
    "(2) 由于我们需要对比Batch Normalization和Base Lines,所以我们需要构建两个函数来分别处理:\n",
    "\n",
    "(2.1)\n",
    "\n",
    "```python\n",
    "def fit_BN(self,Z):\n",
    "    ...```\n",
    "\n",
    "(2.1.1) 对于BN层,我们需要使用```keras.layers.BatchNormalization```并指定```axis=1```一般选择的是特征轴,与TF,Pytorch不同的是Keras不需要对BN的Testing做处理,Keras会自动处理.更多详细查看[BatchNormalization](https://keras.io/zh/layers/normalization/#batchnormalization)\n",
    "\n",
    "(2.1.2) 由于BN层我们不需要初始化bias,所以指定```use_bias=False```\n",
    "\n",
    "(2.1.3) 使用output layer:softmax,hidden layers:relu.\n",
    "\n",
    "\n",
    "(2.2)\n",
    "\n",
    "```python\n",
    "def fit_BL(self,Z):\n",
    "    ...\n",
    "```\n",
    "\n",
    "BL层与普通之前是一样的,这里就不多说了.\n",
    "\n",
    "\n",
    "(3)\n",
    "\n",
    "```python\n",
    "def fit(self,x,y,val_x,val_y):\n",
    "    ...```\n",
    "\n",
    "(3.1) 由于我们需要使用softmax多分类,所以我们需要将labels转换成hot形式:```keras.utils.to_categorical```.\n",
    "\n",
    "(3.2) 构建Model\n",
    "\n",
    "(3.3) 构建optimizer:SGD\n",
    "\n",
    "(3.4) 构建Loss:categorical_crossentropy\n",
    "\n",
    "(3.5) 编译model:```model.compile```\n",
    "\n",
    "(3.6) 训练model,并指定验证样本```validation_data```,使用Tensorbord储存```callbacks=[TensorBoard(...)]```信息.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BN_BL:\n",
    "    \"\"\"\n",
    "    Build Batch Normalization and Base Lines.\n",
    "    \"\"\"\n",
    "    def __init__(self,layers,mode,epochs,lr,batch_size,fielname):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "        ----------\n",
    "            layers: hidden layers. this sample [100,80,50,30,10]\n",
    "            mode: choose BN or BL.\n",
    "            epochs: #Iter.\n",
    "            lr: learning rate.\n",
    "            batch_size: batch size.\n",
    "            fielname: save tensorborder path.\n",
    "        \"\"\"\n",
    "        self.layers = layers\n",
    "        self.mode = mode\n",
    "        self.epochs = epochs\n",
    "        self.lr = lr\n",
    "        self.batch_size = batch_size\n",
    "        self.fielname = fielname\n",
    "        \n",
    "    def fit_BN(self,Z):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "        ----------\n",
    "            Z: first hidden layer input value.\n",
    "        Return:\n",
    "        ------\n",
    "            outputs: last layer output value.\n",
    "        \"\"\"\n",
    "        for l in range(self.L):\n",
    "            Z = Dense(self.layers[l],activation='relu',use_bias=False)(Z)\n",
    "            Z = keras.layers.BatchNormalization(axis=0)(Z) # using BN layer\n",
    "            if l == self.L -1:\n",
    "                Z = Dense(self.layers[-1],activation='softmax',use_bias=False)(Z)\n",
    "                outputs = Z\n",
    "        return outputs\n",
    "    \n",
    "    def fit_BL(self,Z):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "        ----------\n",
    "            Z: first hidden layer input value.\n",
    "        Return:\n",
    "        ------\n",
    "            outputs: last layer output value.\n",
    "        \"\"\"\n",
    "        for l in range(self.L):\n",
    "            Z = Dense(self.layers[l],activation='relu')(Z)\n",
    "            if l == self.L -1:\n",
    "                Z = Dense(self.layers[-1],activation='softmax')(Z)\n",
    "                outputs = Z\n",
    "        return outputs\n",
    "        \n",
    "    def fit(self,x,y,val_x,val_y):\n",
    "        \"\"\"\n",
    "        Fitting Model.\n",
    "        \n",
    "        Parameters:\n",
    "        ----------\n",
    "            x: training date set.\n",
    "            y: training labels.\n",
    "            val_x: validation date.\n",
    "            val_y: validation labels.\n",
    "        \n",
    "        Return:\n",
    "        ------\n",
    "            self.model: Kreas BN_Bl model.\n",
    "            \n",
    "        \"\"\"\n",
    "        \n",
    "        m,n = x.shape\n",
    "        self.n_classes = len(np.unique(y))\n",
    "        \n",
    "        # change hot labels from labels..\n",
    "        y_hot = keras.utils.to_categorical(y,self.n_classes)\n",
    "        val_y_hot = keras.utils.to_categorical(val_y,self.n_classes)\n",
    "        self.L = len(self.layers)\n",
    "        \n",
    "        inputs = Input((n,)) # create input layers\n",
    "        Z = inputs \n",
    "        \n",
    "        # choose running mode.\n",
    "        if self.mode == \"BN\":\n",
    "            outputs = self.fit_BN(Z)\n",
    "        elif self.mode == \"BL\":\n",
    "            outputs = self.fit_BL(Z)\n",
    "        else:\n",
    "            print('Valide mode %s'%self.mode)\n",
    "            \n",
    "        # create Model\n",
    "        self.model = Model(inputs=inputs, outputs=outputs)\n",
    "        # create optimizer\n",
    "        optimizer = keras.optimizers.SGD(lr=self.lr)\n",
    "        # create loss function\n",
    "        Loss_func = keras.losses.categorical_crossentropy\n",
    "        # compile model\n",
    "        self.model.compile(optimizer=optimizer,loss=Loss_func,metrics=['accuracy'])\n",
    "        # fitting model.\n",
    "        self.model.fit(x=x,y=y_hot,batch_size=self.batch_size,epochs=self.epochs,\n",
    "                  validation_data=(val_x,val_y_hot),verbose=0,callbacks=[TensorBoard(log_dir=self.fielname)])\n",
    "        \n",
    "        return self.model\n",
    "        \n",
    "    def score(self,x,y):\n",
    "        \"\"\"\n",
    "        Score model.\n",
    "        Parameters:\n",
    "        ----------\n",
    "            x: score data.\n",
    "            y: score labels.\n",
    "        \"\"\"\n",
    "        y = keras.utils.to_categorical(y,self.n_classes)\n",
    "        loss,acc = self.model.evaluate(x,y)\n",
    "        print('The loss {} acc {}'.format(loss,acc))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing BN and BaseLine\n",
    "\n",
    "测试不同情况下,BN网络与普通网络之间的差异:\n",
    "\n",
    "(1) 小权重,小学习率\n",
    "\n",
    "(2) 小权重,大学习率\n",
    "\n",
    "**Ps:**\n",
    "\n",
    "```keras.backend.clear_session()```清空session,这样Keras才不会进行session叠加,否则产生的网络结构是累加的."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 小权重,小学习率\n",
    "\n",
    "BN:```Tensorborder:small_weights_small_lr_BN```\n",
    "\n",
    "BL:```Tensorborder:small_weights_small_lr_BL```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = [100,80,50,30,10]\n",
    "clf = BN_BL(layers=layers,mode=\"BN\",epochs=1000,lr=0.001,batch_size=60,fielname=\"small_weights_small_lr_BN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/huwang/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /Users/huwang/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.training.Model at 0x127eebe10>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(train_x,train_y,val_x,val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 0s 76us/step\n",
      "The loss 3.3252144145965574 acc 0.29\n"
     ]
    }
   ],
   "source": [
    "clf.score(test_x,test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.training.Model at 0xb354c3b38>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers = [100,80,50,30,10]\n",
    "clf = BN_BL(layers=layers,mode=\"BL\",epochs=1000,lr=0.001,batch_size=60,fielname=\"small_weights_small_lr_BL\")\n",
    "clf.fit(train_x,train_y,val_x,val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 0s 68us/step\n",
      "The loss 7.965495491027832 acc 0.26\n"
     ]
    }
   ],
   "source": [
    "clf.score(test_x,test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 小权重,大学习率\n",
    "\n",
    "BN:```Tensorborder:small_weights_big_lr_BN```\n",
    "\n",
    "BL:```Tensorborder:small_weights_big_lr_BL```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.training.Model at 0xb369b9f28>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers = [100,80,50,30,10]\n",
    "clf = BN_BL(layers=layers,mode=\"BN\",epochs=1000,lr=0.1,batch_size=60,fielname=\"small_weights_big_lr_BN\")\n",
    "clf.fit(train_x,train_y,val_x,val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 0s 69us/step\n",
      "The loss 5.36355712890625 acc 0.38\n"
     ]
    }
   ],
   "source": [
    "clf.score(test_x,test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.training.Model at 0xb378c0ba8>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers = [100,80,50,30,10]\n",
    "clf = BN_BL(layers=layers,mode=\"BL\",epochs=1000,lr=0.1,batch_size=60,fielname=\"small_weights_big_lr_BL\")\n",
    "clf.fit(train_x,train_y,val_x,val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 0s 144us/step\n",
      "The loss 14.8286474609375 acc 0.08\n"
     ]
    }
   ],
   "source": [
    "clf.score(test_x,test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tensorbord"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BN 网络结构\n",
    "\n",
    "<img src=\"../../../picture/59.png\" width=300 heigth=\"300\">\n",
    "BL 网络结构\n",
    "<img src=\"../../../picture/60.png\" width=300 heigth=\"300\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary \n",
    "\n",
    "BN效果显著与BL效果,具体详情查看对应的Tensorbord.\n",
    "\n",
    "**Ps:**\n",
    "\n",
    "val_loss会出现先下降后上升的情况,在loss上升的时候即为开始过拟合,这是正常现象,因为我们没有对数据集和网络做任何处理,此处只是在对比BN与BL."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
