{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  CNN(Tensorflow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.datasets import mnist\n",
    "from tensorflow.python.framework import ops\n",
    "\n",
    "from utils import random_mini_batche_v2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../../picture/tf_CONV.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里我们使用Minist手写数据集,该模型是依据Tensorflow的官方案例而衍生出来的模型.下面我就来看看如何使用Tensorflow来完成该模型."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data \n",
    "\n",
    "这里我们依然使用Keras数据集中的mnist,需要注意的是,为了模型运行效率(CPU),我这里只使用了10K的train set,以及0.1K的validation set.\n",
    "\n",
    "**Ps:**\n",
    "\n",
    "- 原minis数据集大小: train set:60K,validation set 10K."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Load_data(index,limit_train,limit_test):\n",
    "    \"\"\"\n",
    "    Load data set.\n",
    "    Arguments:\n",
    "    ---------\n",
    "        index: show minist digits index.\n",
    "        limit_train: sample limit of training set,in this case, choose 10K.\n",
    "        limit_test: sample limit of validation set,in this case,choose 0,1K.\n",
    "    Returns:\n",
    "    -------\n",
    "        x_train: training data set. divide by 255.-->normal\n",
    "        x_test: testing data set. divide by 255.-->normal\n",
    "        y_train: training data labels. It's a hot vector, shape is (m,n_classes).\n",
    "        y_test: testing data labels,a hot vector,shape is (m,n_classes).\n",
    "    \"\"\"\n",
    "    (X_train,Y_train),(X_test,Y_test) = mnist.load_data()\n",
    "    x_train = X_train[:limit_train,...].reshape(-1,28,28,1)\n",
    "    x_test = X_test[:limit_test,...].reshape(-1,28,28,1)\n",
    "    \n",
    "    n_classes = len(np.unique(Y_train))\n",
    "    y_train = np.eye(n_classes)[Y_train[:limit_train,...]]\n",
    "    y_test = np.eye(n_classes)[Y_test[:limit_test,...]]\n",
    "    \n",
    "    print('x_train reshape:\\n',x_train.shape)\n",
    "    print('x_test reshape:\\n',x_test.shape)\n",
    "    print('Hot y_train shape:\\n ',y_train.shape)\n",
    "    print('Hot y_test shape:\\n ',y_test.shape)\n",
    "    print('The Number is:{}'.format(Y_train[index]))\n",
    "    plt.imshow(X_train[index],cmap='gray')\n",
    "    plt.show()\n",
    "    \n",
    "    return x_train/255,x_test/255,y_train,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train reshape:\n",
      " (10000, 28, 28, 1)\n",
      "x_test reshape:\n",
      " (100, 28, 28, 1)\n",
      "Hot y_train shape:\n",
      "  (10000, 10)\n",
      "Hot y_test shape:\n",
      "  (100, 10)\n",
      "The Number is:5\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_train,x_test,y_train,y_test = Load_data(0,10000,100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到原图展示的效果,接下去我们就要开始搭建CNN模型."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build CNN Model\n",
    "\n",
    "### Initialization Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里我们只初始化卷积层的$Weights,Bias$.因为我们全连接层使用的是\n",
    "\n",
    "[tf.contrib.layers.fully_connected](https://www.tensorflow.org/api_docs/python/tf/contrib/layers/fully_connected):\n",
    "\n",
    "- 该函数会自动创建一个符合大小的$Weights$,并且默认使用```xavier_initializer```初始化.\n",
    "\n",
    "- 该函数会自动创建一个符合大小的$bias$,并且默认使用```zeros_initializer```初始化.\n",
    "\n",
    "我们只需要按照```[batch_size, depth]```的形状输入即可."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_parameters():\n",
    "    \"\"\"\n",
    "    Initialization Parameters.\n",
    "    \n",
    "    Arguments:\n",
    "    ---------\n",
    "        None.\n",
    "    \n",
    "    Returns:\n",
    "    -------\n",
    "        parameters_cache: cache parameters incloud W1,b1,W2,b2\n",
    "    \n",
    "    Note:\n",
    "    ----\n",
    "        W1: 5,5,1,32\n",
    "        b1: 1,1,32\n",
    "        W2: 5,5,32,64\n",
    "        b2: 1,1,64\n",
    "        for example; W1 shape (f_h,f_w,f_c,#f),notic,the f_c must equal input n_c.\n",
    "    \"\"\"\n",
    "    tf.set_random_seed(234)\n",
    "    initial_W = tf.keras.initializers.he_normal(1)\n",
    "    initial_b = tf.keras.initializers.zeros()\n",
    "    W1 = tf.get_variable('W1',[5,5,1,32],initializer=initial_W)\n",
    "    b1 = tf.get_variable('b1',[1,1,32],initializer=initial_b)\n",
    "    W2 = tf.get_variable('W2',[5,5,32,64],initializer=initial_W)\n",
    "    b2 = tf.get_variable('b2',[1,1,64],initializer=initial_b)\n",
    "    \n",
    "    parameters_cache = (W1,b1,W2,b2)\n",
    "    \n",
    "    return parameters_cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward\n",
    "\n",
    "现在我们创建Forward Propagation.\n",
    "\n",
    "模型流程为:\n",
    "\n",
    "Input-->CONV1(28x28x32)-->POOL1(28x28x32)-->CONV2(28x28x64)-->POOl2(28x28x64)-->FC3(1024)-->Output(10).\n",
    "\n",
    "1) 在使用TF的[tf.nn.conv2d](https://www.tensorflow.org/versions/r1.9/api_docs/python/tf/nn/conv2d?hl=en)函数的时候,我们需要注意以下几点.\n",
    "- 0.默认的数据输入形式为```data_format:NHWC```,也就是Number of sample, Height of sample,Width of sameple. Channels of samepl.\n",
    "\n",
    "- 1.input的输入为:```[batch, in_height, in_width, in_channels]```.\n",
    "\n",
    "- 2.kernel的输入为:```[filter_height, filter_width, in_channels, out_channels]```.\n",
    "\n",
    "- 3.可以自己更改输入的形式```data_format:\"NHWC\", \"NCHW\"```\n",
    "\n",
    "- 4.padding可已选择```SAME```或者```VALID```.\n",
    "\n",
    "- 5.strides的输入极为重要,其根据的是```data_format```的选择而言的,因为我们这里选择的是```NHWC```,strides是在```HW```上滑动,所以剩余维度的步长为1,```HW```维度的步长为s,比如我们的s=2,那么```strides=[1,2,2,1]```.\n",
    "\n",
    "2) 在使用[tf.nn.max_pool](https://www.tensorflow.org/api_docs/python/tf/nn/max_pool)函数的时候需要注意以下几点:\n",
    "\n",
    "- 0.输入的形状与```data_format```一致.\n",
    "\n",
    "- 1.卷积核ksize与strides是一致的,依照data_format而言,比如我们的选择的是```NHWC```,那么卷积核的大小也只有在```HW```上,其他维度都为1.比如我们选择$F=2$的卷积核:```ksize=[1,2,2,1]```.\n",
    "\n",
    "3) [tf.contrib.layers.flatten](https://www.tensorflow.org/api_docs/python/tf/contrib/layers/flatten):将数据展平为```[batch_size,...]```的形式,也就是说batch size 先行.\n",
    "\n",
    "4) [tf.nn.dropout](https://www.tensorflow.org/api_docs/python/tf/nn/dropout):使用Dropout,在训练的过程中防止过拟合,需要注意的是:\n",
    "\n",
    "![](../../picture/173.png)\n",
    "\n",
    "也就是说,我们不能使用```keep_prob```,按照官方给出的建议,我们应该选择使用```rate```也就是删除率,亦即```rate=1-keep_prob```.\n",
    "\n",
    "5) 在最后一个全连接层的时候,我们一定不能使用activation,也就是设置```activation_fn=None```,因为我们接下去使用的loss函数是```tf.nn.softmax_cross_entropy_with_logits_v2```,其会将非线性值自动求softmax与损失,所以我们要保证最后一个全连接层为**non-linear!.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(data,parameters,rate):\n",
    "    \"\"\"\n",
    "    Forward Propagation of CNN model.\n",
    "    \n",
    "    Arguments:\n",
    "    ---------\n",
    "        data: training data set,it's a place holder,the shape is (batch_size,height,width,channels).\n",
    "        parameters: include weights and bias.\n",
    "        rate: dropout rate, it's equal 1-keep_prob.\n",
    "        \n",
    "    Retrurns:\n",
    "    --------\n",
    "        A4: Output layers value,It's a non-linear, the shape is (m,n_classes).\n",
    "    \"\"\"\n",
    "    (W1,b1,W2,b2) = parameters\n",
    "    # CONV1\n",
    "    Z1 = tf.nn.conv2d(data,W1,[1,1,1,1],padding='SAME',name='CONV1') + b1\n",
    "    A1 = tf.nn.relu(Z1)\n",
    "    P1 = tf.nn.max_pool(A1,ksize=[1,2,2,1],strides=[1,2,2,1],padding=\"SAME\",name='POOL1')\n",
    "    # CONV2\n",
    "    Z2 = tf.nn.conv2d(P1,W2,[1,1,1,1],padding=\"SAME\",name='CONV2') + b2\n",
    "    A2 = tf.nn.relu(Z2)\n",
    "    P2 = tf.nn.max_pool(A2,ksize=[1,2,2,1],strides=[1,2,2,1],padding='SAME',name='POOL2')\n",
    "    # Flatten\n",
    "    flatten = tf.contrib.layers.flatten(P2)\n",
    "    # FC3\n",
    "    A3 = tf.contrib.layers.fully_connected(flatten,1024)\n",
    "    A3_drop = tf.nn.dropout(A3,rate=rate)\n",
    "    \n",
    "    # FC4 its a non-linear output.\n",
    "    A4 = tf.contrib.layers.fully_connected(A3_drop,10,activation_fn=None)\n",
    "    \n",
    "    return A4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在我们来测试训练集的前100个样本,看看Forward能否走通."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 10)\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "with tf.Session() as sess:\n",
    "    X_tensor = tf.placeholder(tf.float32,[None,28,28,1],name='Input')\n",
    "    rate = tf.placeholder(tf.float32)\n",
    "    parameters_cache = init_parameters()\n",
    "    A5 = forward(X_tensor,parameters_cache,rate)\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    out = sess.run(A5,feed_dict={X_tensor:x_train[:100],rate:0.3})\n",
    "    print(out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK,那么现在已经走通了Forward,我们开始构建CNN Model.\n",
    "\n",
    "### Build CNN Model\n",
    "\n",
    "我们选择使用Adam Optimizer,学习率lr设置为1e-4,Batch_size设置为100.迭代次数epochs设置为6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN_Model(data,labels,val_data,val_labels,epochs,lr,BATC_SIZE):\n",
    "    \"\"\"\n",
    "    Build CNN Model.\n",
    "    \n",
    "    Arguments:\n",
    "    ---------\n",
    "        data: training data set,shape is (m,n_h,n_w,n_c).\n",
    "        labels: training data labels,shape is (m,n_classes).\n",
    "        val_data: validation data set,shape like data shape.\n",
    "        val_labels:validation data set,shape like labels shape.\n",
    "        epochs: number of iterate.\n",
    "        lr: learning rate. I choose 1e-4.\n",
    "        BATC_SIZE: sample batch size of every epoch.\n",
    "    \n",
    "    \"\"\"\n",
    "    ops.reset_default_graph() # reset graph.\n",
    "    m,n_h,n_w,n_c = data.shape\n",
    "    n_classes = labels.shape[1]\n",
    "    # Create place holder .\n",
    "    X = tf.placeholder(tf.float32,(None,n_h,n_w,n_c),name=\"Input\")\n",
    "    y = tf.placeholder(tf.float32,(None,10),name=\"Labels\")\n",
    "    rate = tf.placeholder(tf.float32,name=\"rate\")\n",
    "    \n",
    "    # Forward\n",
    "    parameters = init_parameters()\n",
    "    out = forward(X,parameters,rate)\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=out,labels=y))\n",
    "    optimizer = tf.train.AdamOptimizer(lr).minimize(cost)\n",
    "    \n",
    "    # caculate accuracy.\n",
    "    prediction = tf.nn.softmax(out,axis=1)\n",
    "    correct = tf.equal(tf.argmax(y,axis=1),tf.argmax(prediction,axis=1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct,tf.float32))\n",
    "    \n",
    "    init = tf.global_variables_initializer()\n",
    "    seed = 0\n",
    "    \n",
    "    # Start training model and in each  epoch to print loss and accuracy.\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init)\n",
    "        for epoch in range(epochs):\n",
    "            mini_btahcs = random_mini_batche_v2(data,labels,BATC_SIZE,seed)\n",
    "            \n",
    "            for mini_x,mini_y in mini_btahcs:\n",
    "                _ = sess.run(optimizer,feed_dict={X:mini_x,y:mini_y,rate:0.3})\n",
    "            \n",
    "            if epoch % 1==0:\n",
    "                acc_train,loss_train = sess.run([accuracy,cost],feed_dict={X:data,y:labels,rate:0.})\n",
    "                acc_val,loss_val = sess.run([accuracy,cost],feed_dict={X:val_data,y:val_labels,rate:0.})\n",
    "                print('[{}/{}] Train acc:{:.4f} Train Loss:{:.4f} Val acc:{:.4f} Val Loss:{:.4f}'.format(epoch+1,\n",
    "                                                                                         epochs,\n",
    "                                                                                         acc_train,\n",
    "                                                                                         loss_train,\n",
    "                                                                                         acc_val,\n",
    "                                                                                         loss_val\n",
    "                                                                                        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/6] Train acc:0.9264 Train Loss:0.2455 Val acc:0.9700 Val Loss:0.1939\n",
      "[2/6] Train acc:0.9609 Train Loss:0.1412 Val acc:0.9700 Val Loss:0.1193\n",
      "[3/6] Train acc:0.9750 Train Loss:0.0940 Val acc:0.9800 Val Loss:0.0804\n",
      "[4/6] Train acc:0.9826 Train Loss:0.0699 Val acc:0.9800 Val Loss:0.0593\n",
      "[5/6] Train acc:0.9869 Train Loss:0.0553 Val acc:0.9900 Val Loss:0.0418\n",
      "[6/6] Train acc:0.9889 Train Loss:0.0478 Val acc:0.9900 Val Loss:0.0319\n"
     ]
    }
   ],
   "source": [
    "CNN_Model(x_train,y_train,x_test,y_test,6,lr=1e-4,BATC_SIZE=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到相比与之前的DNN,CNN在4个epoch的时候就已经能达到很高的正确率,并且训练样本与验证样本之前也没有发现过拟合现象."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
