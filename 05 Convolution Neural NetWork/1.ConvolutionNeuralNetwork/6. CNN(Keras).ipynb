{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  CNN(Keras)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../../picture/tf_CONV.png)\n",
    "\n",
    "这里我们使用CNN(Tensorflow)中的模型."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout,Activation,Flatten,Dense\n",
    "from keras.layers import Conv2D,MaxPooling2D\n",
    "from keras.datasets import mnist\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Datasets\n",
    "\n",
    "加载数据和之前是一样的,这里就不在多说了,其数据的形状为:$data:(m,n_h,n_w,n_c),labels:(m,n_{classes})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Load_data(index,limit_train,limit_test):\n",
    "    \"\"\"\n",
    "    Load data set.\n",
    "    Arguments:\n",
    "    ---------\n",
    "        index: show minist digits index.\n",
    "        limit_train: sample limit of training set,in this case, choose 10K.\n",
    "        limit_test: sample limit of validation set,in this case,choose 0,1K.\n",
    "    Returns:\n",
    "    -------\n",
    "        x_train: training data set. divide by 255.-->normal\n",
    "        x_test: testing data set. divide by 255.-->normal\n",
    "        y_train: training data labels. It's a hot vector, shape is (m,n_classes).\n",
    "        y_test: testing data labels,a hot vector,shape is (m,n_classes).\n",
    "    \"\"\"\n",
    "    (X_train,Y_train),(X_test,Y_test) = mnist.load_data()\n",
    "    x_train = X_train[:limit_train,...].reshape(-1,28,28,1)\n",
    "    x_test = X_test[:limit_test,...].reshape(-1,28,28,1)\n",
    "    \n",
    "    n_classes = 10\n",
    "    y_train = keras.utils.to_categorical(Y_train[:limit_train],n_classes)\n",
    "    y_test = keras.utils.to_categorical(Y_test[:limit_test],n_classes)\n",
    "    \n",
    "    print('x_train reshape:\\n',x_train.shape)\n",
    "    print('x_test reshape:\\n',x_test.shape)\n",
    "    print('y_train shape:\\n ',y_train.shape)\n",
    "    print('y_test shape:\\n ',y_test.shape)\n",
    "    print('The Number is:{}'.format(Y_train[index]))\n",
    "    plt.imshow(X_train[index],cmap='gray')\n",
    "    plt.show()\n",
    "    \n",
    "    return x_train/255,x_test/255,y_train,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train reshape:\n",
      " (60000, 28, 28, 1)\n",
      "x_test reshape:\n",
      " (10000, 28, 28, 1)\n",
      "y_train shape:\n",
      "  (60000, 10)\n",
      "y_test shape:\n",
      "  (10000, 10)\n",
      "The Number is:0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_train,x_test,y_train,y_test = Load_data(1,60000,10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras of CNN Model\n",
    "\n",
    "接下去我们使用Keras搭建CNN模型,其网络结构为:\n",
    "\n",
    "Input(28,28,1)-->CONV1(28,28,32)-->Relu1-->MaxPool1(28,28,32)-->CONV2(28,28,64)-->Relu2-->MaxPool2(28,28,64)-->Flatten-->FC3(1024)-->Dropout(0.3)-->FC4(10).\n",
    "\n",
    "[1] [Conv2D](https://keras.io/zh/layers/convolutional/#conv2d)\n",
    "\n",
    "- 遵循默认```cnannels_last```也即是:$(batch,N_h,N_w,N_c)$\n",
    "\n",
    "- filters:卷积核个数\n",
    "\n",
    "- kernel_size: 卷积核形状,int类型($F_h=F_w=int$)或者tuple类型$(F_h,F_w)$\n",
    "\n",
    "- strides:感受野步长,int类型($S_h=S_w=int$)或者tuple类型$(S_h,S_w)$\n",
    "\n",
    "- padding:可以选择\"same\"或者\"valid\",需要注意的是大小写敏感.\n",
    "\n",
    "[2] [MaxPooling2D](https://keras.io/zh/layers/pooling/#maxpooling2d)\n",
    "\n",
    "- 遵循默认```cnannels_last```也即是:$(batch,N_h,N_w,N_c)$\n",
    "\n",
    "- pool_size: 卷积窗口大小,int类型($P_h=P_w=int$)或者tuple类型$(P_h,P_w)$\n",
    "\n",
    "- strides:感受野步长,默认为None,如果是None表示使用$(S_h=S_w=2)$,int类型($S_h=S_w=int$)或者tuple类型$(S_h,S_w)$\n",
    "\n",
    "- padding:可以选择\"same\"或者\"valid\",需要注意的是大小写敏感.\n",
    "\n",
    "[3] [Flatten](https://keras.io/zh/layers/core/#flatten)\n",
    "\n",
    "- 遵循默认```cnannels_last```也即是:$(batch,N_h,N_w,N_c)$\n",
    "\n",
    "- 如果是```cnannels_last```,则输出为```(batch,-1)```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN_Model(data,labels,val_data,val_laebls,epochs,lr,BATCH_SIZE):\n",
    "    \"\"\"\n",
    "    Build Keras of CNN Model.\n",
    "    \n",
    "    Arguments:\n",
    "    ---------\n",
    "        data: training data set,the shape is (m,n_h,n_w,n_c).\n",
    "        labels: training data labels,the shape is (m,n_classes).\n",
    "        val_data: validation data set,shape equal data's shape.\n",
    "        val_laebls: validation labels,shape equal labels's shape.\n",
    "        epochs: Number of iterate.\n",
    "        lr: learning rate.\n",
    "        BATCH_SIZE: batch size.\n",
    "    Return:\n",
    "    ------\n",
    "        model: keras model.\n",
    "    \"\"\"\n",
    "    \n",
    "    _,n_clsses = labels.shape\n",
    "    model = Sequential() # create Sequential model.\n",
    "    ################ start build Keras of CNN Model #######################################################\n",
    "    model.add(Conv2D(filters=32,kernel_size=(5,5),strides=(1,1),padding='same',input_shape=data.shape[1:]))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2),padding='same'))\n",
    "    model.add(Conv2D(filters=64,kernel_size=(5,5),strides=(1,1),padding='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2),padding='same'))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1024))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(n_clsses))\n",
    "    model.add(Activation('softmax'))\n",
    "    ################# end of CNN model #####################################################################\n",
    "    optimizer = keras.optimizers.adam(lr=lr)\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                 optimizer = optimizer,\n",
    "                 metrics=['accuracy'])\n",
    "    \n",
    "    model.fit(data,labels,batch_size=BATCH_SIZE,epochs=epochs,validation_data=(val_data,val_laebls),shuffle=True)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/6\n",
      "60000/60000 [==============================] - 120s 2ms/step - loss: 0.2935 - acc: 0.9180 - val_loss: 0.0819 - val_acc: 0.9752\n",
      "Epoch 2/6\n",
      "60000/60000 [==============================] - 123s 2ms/step - loss: 0.0783 - acc: 0.9765 - val_loss: 0.0503 - val_acc: 0.9835\n",
      "Epoch 3/6\n",
      "60000/60000 [==============================] - 121s 2ms/step - loss: 0.0552 - acc: 0.9839 - val_loss: 0.0360 - val_acc: 0.9879\n",
      "Epoch 4/6\n",
      "60000/60000 [==============================] - 123s 2ms/step - loss: 0.0436 - acc: 0.9868 - val_loss: 0.0322 - val_acc: 0.9896\n",
      "Epoch 5/6\n",
      "60000/60000 [==============================] - 130s 2ms/step - loss: 0.0361 - acc: 0.9889 - val_loss: 0.0289 - val_acc: 0.9898\n",
      "Epoch 6/6\n",
      "60000/60000 [==============================] - 140s 2ms/step - loss: 0.0301 - acc: 0.9911 - val_loss: 0.0309 - val_acc: 0.9891\n"
     ]
    }
   ],
   "source": [
    "model = CNN_Model(x_train,y_train,x_test,y_test,epochs=6,lr=1e-4,BATCH_SIZE=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到经过6个epoch后,train acc为0.9911,val acc为0.9891,结果是可以接受的."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Model And Load Model\n",
    "\n",
    "保存模型,我们只需要运行```model.save```即可,给予的数据格式是```h5```,所以需要确保已经安装了```HDFF5```模块.\n",
    "\n",
    "加载模型,我们只需要运行```load_model```即可,给予保存时候的文件```.h5```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SaveModel(model,model_name,model_dir='keras_save_model'):\n",
    "    \"\"\"\n",
    "    Save Model.\n",
    "    \n",
    "    Arguments:\n",
    "    ---------\n",
    "        model: keras model.\n",
    "        model_name: model name,it's \".h5\" file.\n",
    "        model_dir: dir default \"./keras_save_model/\"\n",
    "    \"\"\"\n",
    "    import os\n",
    "    if not os.path.isdir(model_dir):\n",
    "        os.mkdir(model_dir)\n",
    "    model_path = os.path.join(model_dir,model_name)\n",
    "    model.save(model_path)\n",
    "    print('Model Saved at %s'% model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved at keras_save_model/mnist_model.h5\n"
     ]
    }
   ],
   "source": [
    "SaveModel(model,'mnist_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "保存好模型之后,我们加载模型并预测训练集的前两个样本."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LoadModel(model_path,data,labels):\n",
    "    \"\"\"\n",
    "    Load model.\n",
    "    \n",
    "    Arguments:\n",
    "    ---------\n",
    "        model_path: save model path, it's \".h5\" file.\n",
    "        data: predict data.\n",
    "    \"\"\"\n",
    "    from keras.models import load_model\n",
    "    \n",
    "    model = load_model(model_path)\n",
    "    predict = np.argmax(model.predict(data),axis=1)\n",
    "    for i,value in enumerate(predict):\n",
    "        print('The {} picture,predict:{},the ture label:{}'.format(i,value,np.argmax(labels[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 0 picture,predict:5,the ture label:5\n",
      "The 1 picture,predict:0,the ture label:0\n"
     ]
    }
   ],
   "source": [
    "LoadModel('keras_save_model/mnist_model.h5',x_train[:2],y_train[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "另外还有其他保存模型并调用的方式;\n",
    "\n",
    "第一种是只保存权重而不保存模型的结构:\n",
    "\n",
    "```python\n",
    "# save and load weights\n",
    "model.save_weights('my_model_weights.h5')\n",
    "model.load_weights('my_model_weights.h5')```\n",
    "\n",
    "第二种是用```model.to_json```保存完结构之后,然后再去加载这个```json_string```.\n",
    "\n",
    "```python\n",
    "# save and load fresh network without trained weights\n",
    "from keras.models import model_from_json\n",
    "json_string = model.to_json()\n",
    "model = model_from_json(json_string)```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
