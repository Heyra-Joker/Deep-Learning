{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LeNet-5(Pytorch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../../../picture/177.png)\n",
    "该模型是原文模型,在C3层以及最后的Gaussian Connections是比较难实现的.我们目前而言对该模型做一些调整:\n",
    "\n",
    "- 原文sigmoid激活函数,更改为ReLu函数\n",
    "\n",
    "- C3层依然使用普通采样\n",
    "\n",
    "- 由于输入为$(32,32)$,Minis数据集为$(28,28)$,所以我们输入层需要padding.\n",
    "\n",
    "- 输出层我们不再采用Gaussian connection,转而使用softmax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as Data\n",
    "from torch.autograd import Variable\n",
    "from keras.datasets import mnist\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset\n",
    "\n",
    "这里使用Keras数据集中的Minist数据集,train set 60K,test set 10K.\n",
    "\n",
    "这里将样本拆分为: train set 60K,validation set 7K, test set 3K.同时将样本reshape为$(1,28,28)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadDataset(index,split_rate):\n",
    "    \"\"\"\n",
    "    Load data set.\n",
    "    \n",
    "    Arguments:\n",
    "    ---------\n",
    "        index: show index images.\n",
    "        split_rate: validation set and test set split rate.\n",
    "    \n",
    "    Returns:\n",
    "    -------\n",
    "        x_train: training set shape is (m,n_c,n_h,n_w)\n",
    "        y_train: training labels shape is (m,)\n",
    "        x_val: validation set shape is (m,n_c,n_h,n_w)\n",
    "        y_val: validation labels shape is (m,)\n",
    "        x_test: testing set shape is (m,n_c,n_h,n_w)\n",
    "        y_test: testing labels shape is (m,)\n",
    "    \"\"\"\n",
    "    (x_train,y_train),(X,Y) = mnist.load_data()\n",
    "\n",
    "    \n",
    "    plt.imshow(x_train[index],cmap='gray')\n",
    "    plt.show()\n",
    "    \n",
    "    x_train,X = x_train / 255,X/255\n",
    "    x_val, x_test, y_val, y_test = train_test_split(X, Y, test_size=split_rate)\n",
    "    \n",
    "    x_train = x_train.reshape((-1,1,28,28))\n",
    "    x_val = x_val.reshape((-1,1,28,28))\n",
    "    x_test = x_test.reshape((-1,1,28,28))\n",
    "    \n",
    "    print('Training Set shape is:\\n',x_train.shape)\n",
    "    print('Training Labels shape is:\\n',y_train.shape)\n",
    "    print('Validation Set shape is:\\n',x_val.shape)\n",
    "    print('Validation Labels shape is:\\n',y_val.shape)\n",
    "    print('Testing Set shape is:\\n',x_test.shape)\n",
    "    print('Testing Labels shape is:\\n',y_test.shape)\n",
    "    \n",
    "    return x_train,y_train,x_val,y_val,x_test,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set shape is:\n",
      " (60000, 1, 28, 28)\n",
      "Training Labels shape is:\n",
      " (60000,)\n",
      "Validation Set shape is:\n",
      " (7000, 1, 28, 28)\n",
      "Validation Labels shape is:\n",
      " (7000,)\n",
      "Testing Set shape is:\n",
      " (3000, 1, 28, 28)\n",
      "Testing Labels shape is:\n",
      " (3000,)\n"
     ]
    }
   ],
   "source": [
    "x_train,y_train,x_val,y_val,x_test,y_test = loadDataset(10,0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward\n",
    "\n",
    "接下去我们来构建Forward.网络结构为:\n",
    "\n",
    "INPUT(batch,1,32,32)-->CONV1(batch,6,28,28)-->Relu1-->Average Pool1(batch,6,14,14)-->CONV2(batch,16,10,10)-->ReLu2-->Average Pool2(16,5,5)-->FC3(batch,120)-->FC4(batch,84)-->FC5(batch,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Module(nn.Module):\n",
    "    \"\"\"\n",
    "    Build Forward Class Model.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initialization Class Module.\n",
    "        \"\"\"\n",
    "        nn.Module.__init__(self)\n",
    "        # CONV layers\n",
    "        self.CONV = nn.ModuleList([\n",
    "            nn.Conv2d(1,6,kernel_size=(5,5),stride=(1,1)),\n",
    "            nn.ReLU(),\n",
    "            nn.AvgPool2d(kernel_size=(2,2),stride=(2,2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(6,16,kernel_size=(5,5),stride=(1,1)),\n",
    "            nn.ReLU(),\n",
    "            nn.AvgPool2d(kernel_size=(2,2),stride=(2,2)),\n",
    "        ])\n",
    "        # Fully Connect layers.\n",
    "        self.FULLY_CONNECT = nn.ModuleList([\n",
    "            nn.Linear(400,120),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(120,84),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(84,10)\n",
    "        ])\n",
    "        # Change initialize weight in CONV and FC.\n",
    "        [nn.init.xavier_normal_(m.weight) for m in self.CONV if m.__class__.__name__ != \"ReLU\" and m.__class__.__name__ != \"AvgPool2d\"]\n",
    "        [nn.init.xavier_normal_(m.weight) for m in self.FULLY_CONNECT if m.__class__.__name__ != \"ReLU\"]\n",
    "        \n",
    "    def forward(self,X):\n",
    "        \"\"\"\n",
    "        Forward propagation.\n",
    "        \n",
    "        Arguments:\n",
    "        ---------\n",
    "            X: training data set.\n",
    "        Return:\n",
    "        ------\n",
    "            X: output layer value, the shape is (batch,n_classes).\n",
    "        Notic:\n",
    "        ------\n",
    "            1.The output layers must be not use any activation function ! We use nn.CrossEntropyLoss() loss func.\n",
    "            2.The papaer Input shape is (32,32),so we need pad=2 data.\n",
    "            \n",
    "        \"\"\"\n",
    "        X = nn.functional.pad(X,pad=(2,2,2,2)) # padding_left,padding_right,padding_top,padding_bottom\n",
    "        for layer_c in self.CONV:\n",
    "            X = layer_c(X)\n",
    "        \n",
    "        m,_,_,_ = X.size()\n",
    "        X = torch.reshape(X,(m,-1)) # flatten data,shape is (batch,-1)\n",
    "        \n",
    "        for layer_f in self.FULLY_CONNECT:\n",
    "            X = layer_f(X)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000, 10])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    X_test = Variable(torch.FloatTensor(x_train))\n",
    "model = Module()\n",
    "out = model.forward(X_test)\n",
    "out.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到Forward能够完整运行,并输出正确的shape."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score\n",
    "\n",
    "创建评分函数,用于在一定的epoch内评分数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Score(model,cost,data,labels,is_loss=False):\n",
    "    \"\"\"\n",
    "    Socre function.\n",
    "    \n",
    "    Arguments:\n",
    "    ---------\n",
    "       cost: cost function to caculate loss value.\n",
    "       data: score data, the shape is (m,n_c,n_h,n_w).\n",
    "       labels: score data labes. The shape is (m,)\n",
    "       is_loss: caculate loss value,if is equal True.\n",
    "    Returns:\n",
    "    -------\n",
    "        accuracy: correct rate in current epoch.\n",
    "        loss: loss value in currcet epoch,if is euqal True.\n",
    "    \"\"\"\n",
    "    model.eval() # set module is testing !\n",
    "    \n",
    "    out = model.forward(data)\n",
    "    \n",
    "    predict = torch.argmax(nn.functional.softmax(out,dim=-1),dim=1)\n",
    "    correct = torch.eq(predict,labels).type(torch.FloatTensor)\n",
    "    accuracy = torch.mean(correct)\n",
    "    \n",
    "    if is_loss:\n",
    "        loss = cost(out,labels)\n",
    "        return accuracy,loss\n",
    "    else:\n",
    "        return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytorch of LeNet-5 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LeNet_5Model(data,labels,val_data,val_labes,test_data,test_labels,epochs,lr,BATCH_SIZE):\n",
    "    \"\"\"\n",
    "    Implemention LeNet-5 Model.\n",
    "    \n",
    "    Arguments:\n",
    "    ---------\n",
    "        \n",
    "     Arguments:\n",
    "    ---------\n",
    "        data: training data set, the shape is (m,n_c,n_h,n_w).\n",
    "        labels: training labels, the shape is (m,).\n",
    "        val_data: validation data set, the shape is (m,n_c,n_h,b_w).\n",
    "        val_labels: validation labels, the shape is (m,).\n",
    "        test_data: testing data set, the shape is (m,n_c,n_h,n_w).\n",
    "        test_labels: tesing labels, the shape is (m).\n",
    "        epochs: number of iterate. \n",
    "        lr: learning rate to use in RMSProp optimizer.\n",
    "        BATCH_SIZE: epoch size.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # set score func data.\n",
    "    with torch.no_grad():\n",
    "        data_tensor = Variable(torch.FloatTensor(data))\n",
    "        labels_tensor = Variable(torch.LongTensor(labels))\n",
    "        val_data_tensor = Variable(torch.FloatTensor(val_data))\n",
    "        val_labels_tensor = Variable(torch.LongTensor(val_labes))\n",
    "        test_data_tensor = Variable(torch.FloatTensor(test_data))\n",
    "        test_labels_tensor = Variable(torch.LongTensor(test_labels))\n",
    "    \n",
    "    # create model \n",
    "    model = Module()\n",
    "    cost = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.RMSprop(model.parameters(),lr=lr)\n",
    "    \n",
    "    # create mini-batchs data.\n",
    "    X = Variable(torch.FloatTensor(data))\n",
    "    y = Variable(torch.LongTensor(labels))\n",
    "    data_set = Data.TensorDataset(X,y)\n",
    "    loder = Data.DataLoader(dataset=data_set,batch_size=BATCH_SIZE,shuffle=True,num_workers=2)\n",
    "    \n",
    "    # start training\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for mini_x,mini_y in loder:\n",
    "            out = model.forward(mini_x) # forward\n",
    "            loss = cost(out,mini_y) # caculate loss\n",
    "            optimizer.zero_grad() # clear grad\n",
    "            loss.backward() # backward\n",
    "            optimizer.step() # update\n",
    "        # score\n",
    "        if epoch % 1 == 0:\n",
    "            acc_train,loss_train = Score(model,cost,data_tensor,labels_tensor,is_loss=True)\n",
    "            acc_val,loss_val = Score(model,cost,val_data_tensor,val_labels_tensor,is_loss=True)\n",
    "            print('[{}/{}] train loss:{:.4f} train acc:{:.4f} val loss:{:.4f} val acc:{:.4f}'.format(epoch+1,\n",
    "                                                                                                    epochs,\n",
    "                                                                                                    loss_train,\n",
    "                                                                                                    acc_train,\n",
    "                                                                                                    loss_val,\n",
    "                                                                                                    acc_val))\n",
    "    print('Start Testing...')\n",
    "    acc_train,loss_train = Score(model,cost,test_data_tensor,test_labels_tensor,is_loss=True)\n",
    "    print('\\033[0;35m The Testing Set Loss:{:.4f} Accuracy:{:.4f}\\033[0m'.format(loss_train,acc_train))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/10] train loss:0.4080 train acc:0.8767 val loss:0.3843 val acc:0.8849\n",
      "[2/10] train loss:0.3032 train acc:0.9074 val loss:0.2838 val acc:0.9130\n",
      "[3/10] train loss:0.2432 train acc:0.9273 val loss:0.2280 val acc:0.9291\n",
      "[4/10] train loss:0.2028 train acc:0.9388 val loss:0.1922 val acc:0.9409\n",
      "[5/10] train loss:0.1673 train acc:0.9518 val loss:0.1568 val acc:0.9537\n",
      "[6/10] train loss:0.1397 train acc:0.9588 val loss:0.1297 val acc:0.9611\n",
      "[7/10] train loss:0.1211 train acc:0.9641 val loss:0.1131 val acc:0.9670\n",
      "[8/10] train loss:0.1147 train acc:0.9655 val loss:0.1096 val acc:0.9671\n",
      "[9/10] train loss:0.1050 train acc:0.9686 val loss:0.0965 val acc:0.9694\n",
      "[10/10] train loss:0.0940 train acc:0.9710 val loss:0.0876 val acc:0.9703\n",
      "Start Testing...\n",
      "\u001b[0;35m The Testing Set Loss:0.0883 Accuracy:0.9723\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "LeNet_5Model(x_train,y_train,x_val,y_val,x_test,y_test,epochs=10,lr=1e-4,BATCH_SIZE=100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
