{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LeNet-5(Tensorflow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../../../picture/177.png)\n",
    "该模型是原文模型,在C3层以及最后的Gaussian Connections是比较难实现的.我们目前而言对该模型做一些调整:\n",
    "\n",
    "- 原文sigmoid激活函数,更改为ReLu函数\n",
    "\n",
    "- C3层依然使用普通采样\n",
    "\n",
    "- 由于输入为$(32,32)$,Minis数据集为$(28,28)$,所以我们输入层需要padding.\n",
    "\n",
    "- 输出层我们不再采用Gaussian connection,转而使用softmax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.datasets import mnist\n",
    "from utils import random_mini_batche_v2\n",
    "from tensorflow.python.framework import ops\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset\n",
    "\n",
    "这里使用Keras数据集中的Minist数据集,train set 60K,test set 10K.\n",
    "\n",
    "这里将样本拆分为: train set 60K,validation set 7K, test set 3K.同时将样本reshape为$(28,28,1)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadDataset(index,split_rate):\n",
    "    (x_train,y_train),(X,Y) = mnist.load_data()\n",
    "    n_classes = 10\n",
    "    \n",
    "    plt.imshow(x_train[index],cmap='gray')\n",
    "    plt.show()\n",
    "    \n",
    "    x_train,X = x_train / 255,X/255\n",
    "    x_val, x_test, y_val, y_test = train_test_split(X, Y, test_size=split_rate)\n",
    "    \n",
    "    y_train = np.eye(n_classes)[y_train]\n",
    "    y_val = np.eye(n_classes)[y_val]\n",
    "    y_test = np.eye(n_classes)[y_test]\n",
    "    \n",
    "    x_train = x_train.reshape((-1,28,28,1))\n",
    "    x_val = x_val.reshape((-1,28,28,1))\n",
    "    x_test = x_test.reshape((-1,28,28,1))\n",
    "    \n",
    "    print('Training Set shape is:\\n',x_train.shape)\n",
    "    print('Training Labels shape is:\\n',y_train.shape)\n",
    "    print('Validation Set shape is:\\n',x_val.shape)\n",
    "    print('Validation Labels shape is:\\n',y_val.shape)\n",
    "    print('Testing Set shape is:\\n',x_test.shape)\n",
    "    print('Testing Labels shape is:\\n',y_test.shape)\n",
    "    return x_train,y_train,x_val,y_val,x_test,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set shape is:\n",
      " (60000, 28, 28, 1)\n",
      "Training Labels shape is:\n",
      " (60000, 10)\n",
      "Validation Set shape is:\n",
      " (7000, 28, 28, 1)\n",
      "Validation Labels shape is:\n",
      " (7000, 10)\n",
      "Testing Set shape is:\n",
      " (3000, 28, 28, 1)\n",
      "Testing Labels shape is:\n",
      " (3000, 10)\n"
     ]
    }
   ],
   "source": [
    "x_train,y_train,x_val,y_val,x_test,y_test = loadDataset(10,0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization Parameters\n",
    "\n",
    "接下来初始化参数,这里只需要初始化CONV layer,由于我们使用的是```tf.contrib.layers.fully_connected```所以并不需要初始化FC层的$Weights,Bias$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_parameters():\n",
    "    \"\"\"\n",
    "    Initialization parameters:\n",
    "    \n",
    "    Note:\n",
    "    ----\n",
    "        The Weights shape is (f_h,f_w,f_c,f_m), f_c = n_c.\n",
    "        The bias shape is (1,1,f_m)\n",
    "    Return:\n",
    "    ------\n",
    "        parameters: include weights1,2 and bias1,2.\n",
    "    \"\"\"\n",
    "    init_W = tf.keras.initializers.he_normal(1) # set he normal initialize.\n",
    "    init_b = tf.zeros_initializer()\n",
    "    W1 = tf.get_variable('W1',[5,5,1,6],initializer=init_W)\n",
    "    b1 = tf.get_variable('b1',[1,1,6],initializer=init_b)\n",
    "    W2 = tf.get_variable('W2',[5,5,6,16],initializer=init_W)\n",
    "    b2 = tf.get_variable('b2',[1,1,16],initializer=init_b)\n",
    "    \n",
    "    parameters = (W1,b1,W2,b2)\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward\n",
    "\n",
    "构建Forward Propagation.\n",
    "\n",
    "网络构成为:\n",
    "\n",
    "INPUT(batch,32,32,1)-->CONV1(batch,28,28,6)-->Relu1-->Average Pool1(batch,14,14,6)-->CONV2(batch,10,10,16)-->ReLu2-->Average Pool2(5,5,16)-->FC3(batch,120)-->FC4(batch,84)-->FC5(batch,10).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(X,parameters):\n",
    "    \"\"\"\n",
    "    Forward Propagation \n",
    "    \n",
    "    Arguments:\n",
    "    ---------\n",
    "        X: training data set, the shape is (batch,n_h,n_w,n_c)\n",
    "        parameters: include weights and bias ,weights shape is (f_h,f_w,f_c,f_m),bias shape is (1,1,f_m).\n",
    "    \n",
    "    Returns:\n",
    "    -------\n",
    "        Z5: The output values. Have not use activation function !!!.\n",
    "    \"\"\"\n",
    "    (W1,b1,W2,b2) = parameters\n",
    "   \n",
    "    Z1 = tf.nn.conv2d(X,W1,strides=[1,1,1,1],name='CONV1',padding='VALID') + b1\n",
    "    A1 = tf.nn.relu(Z1,name='ReLu1')\n",
    "    P1 = tf.nn.avg_pool(A1,[1,2,2,1],strides=[1,2,2,1],name='Pool1',padding=\"VALID\")\n",
    "    \n",
    "    Z2 = tf.nn.conv2d(P1,W2,strides=[1,1,1,1],name='CONV2',padding=\"VALID\") + b2\n",
    "    A2 = tf.nn.relu(Z2,name='ReLu2')\n",
    "    P2 = tf.nn.avg_pool(A2,[1,2,2,1],strides=[1,2,2,1],name='Pool2',padding=\"VALID\")\n",
    "    \n",
    "    Flatten = tf.layers.flatten(P2,name='Flatten')\n",
    "    Z3 = tf.contrib.layers.fully_connected(inputs=Flatten,num_outputs=120)\n",
    "    A3 = tf.nn.relu(Z3)\n",
    "    Z4 = tf.contrib.layers.fully_connected(inputs=A3,num_outputs=84)\n",
    "    A4 = tf.nn.relu(Z4)\n",
    "    # Must set the activation_fn equal None !!\n",
    "    Z5 = tf.contrib.layers.fully_connected(inputs=A4,num_outputs=10,activation_fn=None)\n",
    "    \n",
    "    return Z5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面我们来测试一下Forward.首先我们需要将$(28,28)$的输入pad到$(32,32)$,其中pad=2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape is:\n",
      " (60000, 32, 32, 1)\n",
      "Output shape is:\n",
      " (60000, 10)\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "with tf.Session() as sess:\n",
    "    X = tf.placeholder(tf.float32,[None,32,32,1])\n",
    "    parameters = init_parameters()\n",
    "    test_X = np.pad(x_train,pad_width=((0,0),(2,2),(2,2),(0,0)),mode='constant')\n",
    "    print(\"Input shape is:\\n\",test_X.shape)\n",
    "    out = forward(X,parameters)\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    out_shape = sess.run(out,feed_dict={X:test_X}).shape\n",
    "    print('Output shape is:\\n',out_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到Forward能够顺利运行."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create LeNet-5 Model\n",
    "\n",
    "下面开始搭建LeNet-5 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LeNet_5Model(data,labels,val_data,val_labels,test_data,test_labels,epochs,lr,BATCH_SIZE):\n",
    "    \"\"\"\n",
    "    Implemention LeNet-5 Module.\n",
    "    \n",
    "    Arguments:\n",
    "    ---------\n",
    "        data: training data set, the shape is (m,n_h,n_w,n_c).\n",
    "        labels: training labels, the shape is (m,n_classes).\n",
    "        val_data: validation data set, the shape is (m,n_h,n_w,n_c).\n",
    "        val_labels: validation labels, the shape is (m,n_classes).\n",
    "        test_data: testing data set, the shape is (m,n_h,n_w,n_c).\n",
    "        test_labels: tesing labels, the shape is (m,n_classes).\n",
    "        epochs: number of iterate. \n",
    "        lr: learning rate to use in RMSProp optimizer.\n",
    "        BATCH_SIZE: epoch size.\n",
    "    \n",
    "    \"\"\"\n",
    "    ops.reset_default_graph()\n",
    "    \n",
    "    ############################ padding data ####################################\n",
    "    data = np.pad(data,pad_width=((0,0),(2,2),(2,2),(0,0)),mode='constant')\n",
    "    val_data = np.pad(val_data,pad_width=((0,0),(2,2),(2,2),(0,0)),mode='constant')\n",
    "    test_data = np.pad(test_data,pad_width=((0,0),(2,2),(2,2),(0,0)),mode='constant')\n",
    "    ############################### end of padded ###################################\n",
    "    \n",
    "    m,n_h,n_w,n_c = data.shape\n",
    "    n_classes = labels.shape[1]\n",
    "    # Create PlaceHolder\n",
    "    X = tf.placeholder(tf.float32,[None,n_h,n_w,n_c],name='Input')\n",
    "    y = tf.placeholder(tf.float32,[None,n_classes],name='Labels')\n",
    "    \n",
    "    # Forward propagation\n",
    "    parameters = init_parameters()\n",
    "    out = forward(X,parameters)\n",
    "    # Caculate loss.\n",
    "    Cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=out,labels=y))\n",
    "    # Use RMSProp optimizer.\n",
    "    optimizer = tf.train.RMSPropOptimizer(learning_rate=lr).minimize(Cost)\n",
    "    \n",
    "    # Caculate accuracy.\n",
    "    predict = tf.argmax(tf.nn.softmax(out,axis=1),axis=1)\n",
    "    correct = tf.equal(predict,tf.argmax(y,axis=1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct,tf.float32))\n",
    "    \n",
    "    seed = 0\n",
    "    \n",
    "    init = tf.global_variables_initializer()\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init)\n",
    "        print('Start Training ...')\n",
    "        for epoch in range(epochs):\n",
    "            seed += 1\n",
    "            batchs = random_mini_batche_v2(data,labels,BATCH_SIZE,seed)\n",
    "            for mini_x,mini_y in batchs:\n",
    "                \n",
    "                sess.run(optimizer,feed_dict={X:mini_x,y:mini_y})\n",
    "\n",
    "            if epoch % 1 == 0:\n",
    "                acc_train,loss_train = sess.run([accuracy,Cost],feed_dict={X:data,y:labels})\n",
    "                acc_val,loss_val = sess.run([accuracy,Cost],feed_dict={X:val_data,y:val_labels})\n",
    "                print('[{}/{}] train loss:{:.4f} train acc:{:.4f} val loss:{:.4f} val acc:{:.4f}'.format(epoch+1,\n",
    "                                                                                                        epochs,\n",
    "                                                                                                        loss_train,\n",
    "                                                                                                        acc_train,\n",
    "                                                                                                        loss_val,\n",
    "                                                                                                        acc_val))\n",
    "        print('Start Testing ...')\n",
    "        acc_test,loss_test = sess.run([accuracy,Cost],feed_dict={X:test_data,y:test_labels})\n",
    "        print('\\033[0;35m The Testing Set Loss:{:.4f} Accuracy:{:.4f}\\033[0m'.format(loss_test,acc_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training ...\n",
      "[1/10] train loss:0.4258 train acc:0.8804 val loss:0.4046 val acc:0.8883\n",
      "[2/10] train loss:0.2671 train acc:0.9226 val loss:0.2554 val acc:0.9267\n",
      "[3/10] train loss:0.2041 train acc:0.9398 val loss:0.1923 val acc:0.9440\n",
      "[4/10] train loss:0.1607 train acc:0.9527 val loss:0.1517 val acc:0.9551\n",
      "[5/10] train loss:0.1318 train acc:0.9613 val loss:0.1281 val acc:0.9616\n",
      "[6/10] train loss:0.1092 train acc:0.9680 val loss:0.1033 val acc:0.9689\n",
      "[7/10] train loss:0.1002 train acc:0.9703 val loss:0.0956 val acc:0.9711\n",
      "[8/10] train loss:0.0858 train acc:0.9747 val loss:0.0801 val acc:0.9769\n",
      "[9/10] train loss:0.0856 train acc:0.9744 val loss:0.0816 val acc:0.9740\n",
      "[10/10] train loss:0.0699 train acc:0.9794 val loss:0.0670 val acc:0.9800\n",
      "Start Testing ...\n",
      "\u001b[0;35m The Testing Set Loss:0.0657 Accuracy:0.9813\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "LeNet_5Model(x_train,y_train,x_val,y_val,x_test,y_test,10,lr=1e-4,BATCH_SIZE=100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
